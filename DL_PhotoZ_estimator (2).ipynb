{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>import and set up some definitions of classes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>This Model uses only the sixth channel as inputs; drastically different than anything else we have tried</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "\n",
    "#model variables\n",
    "batch_size = 256 #32\n",
    "epoch_number = 5 #when ready to test, set to 25\n",
    "learning_rate = 1e-4\n",
    "n_classes = 1\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "params_train = {'dim': (120,),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': n_classes,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "params_test = {'dim': (120,),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': n_classes,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(120,120), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "     #   'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "    #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "    #'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "    # Initialization\n",
    "        X_return = np.empty((self.batch_size, 13))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "    \n",
    "\n",
    "      # Generate data and perform augmentation\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "\n",
    "            #Load Magnitude array and place in 6th channel\n",
    "            string = ID.split('_') #list looks like ['HP','00000']\n",
    "            #print(string)\n",
    "            string = string[0] +'_'+ string[1] + '_sixth' +'.npy'\n",
    "            if ID[:2] == 'HP':\n",
    "                X = np.load('..\\\\DATA\\\\HP_sixth\\\\'+string)[0,:]\n",
    "            if ID[:2] == 'LP':\n",
    "                X = np.load('..\\\\DATA\\\\LP_sixth\\\\'+string)[0,:]\n",
    "            if ID[:2] == 'MP':\n",
    "                X = np.load('..\\\\DATA\\\\MP_sixth\\\\'+string)[0,:]\n",
    "            \n",
    "            #get information:\n",
    "            mu = [X[0]] #dereddened magnitudes\n",
    "            mg = [X[6]]\n",
    "            mr = [X[12]]\n",
    "            mi = [X[18]]\n",
    "            mz = [X[24]]\n",
    "\n",
    "            #pu = [X[i,30]] #petro_r in each band\n",
    "            #pg = [X[i,36]]\n",
    "            #pr = [X[i,42]]\n",
    "            #pi = [X[i,48]]\n",
    "            #pz = [X[i,54]]\n",
    "\n",
    "            cu = [X[60]] #colors, dereddened, and each like u-g, g-r ... z\n",
    "            cg = [X[66]]\n",
    "            cr = [X[72]]\n",
    "            ci = [X[78]]\n",
    "            cz = [X[84]]\n",
    "\n",
    "            pr_20 = [X[90]] #angular size \n",
    "            pr_50 = [X[102]]\n",
    "            pr_90 = [X[114]]\n",
    "\n",
    "\n",
    "            X_return[i,:] = np.array((mu+mg+mr+mi+mz+cu+cg+cr+ci+cz+pr_20+pr_50+pr_90))\n",
    "            \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "            #determine which class it should be...\n",
    "            y[i] = int(round((y[i] / 0.4)*(self.n_classes-1),0))\n",
    "            if y[i] > self.n_classes - 1: #if above 0.4, essentially a far outlier: set to our highest redshift bin.\n",
    "                y[i] = self.n_classes - 1\n",
    "    \n",
    "        if self.n_classes > 2:\n",
    "            return X_return, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X_return, y\n",
    "\n",
    "    def __len__(self):\n",
    "    #'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    #  'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "      # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Set up structure of training data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets are generated in a technical notebook, load them in here.\n",
    "with open(\"..\\\\misc\\\\Z_Spectro.txt\",\"r\") as inf:\n",
    "    targets = eval(inf.read()) #is a dictionary that looks like: {alias:Spectro_Z}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_list = os.listdir(\"..\\\\DATA\\\\HP_inputs\")\n",
    "random.shuffle(data_list)\n",
    "\n",
    "for i,file in enumerate(data_list):\n",
    "    data_list[i] = file.split('.')[0]\n",
    "\n",
    "LP_data_list = os.listdir(\"..\\\\DATA\\\\LP_inputs\")\n",
    "random.shuffle(LP_data_list)\n",
    "\n",
    "for i,file in enumerate(LP_data_list):\n",
    "    LP_data_list[i] = file.split('.')[0]\n",
    "    \n",
    "MP_data_list = os.listdir(\"..\\\\DATA\\\\MP_inputs\")\n",
    "random.shuffle(MP_data_list)\n",
    "\n",
    "for i,file in enumerate(MP_data_list):\n",
    "    MP_data_list[i] = file.split('.')[0]\n",
    "\n",
    "data_list = data_list + LP_data_list + MP_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "last= -1.0 #accept first value\n",
    "limit = 0.055\n",
    "list_for_this = []\n",
    "list_to_save = []\n",
    "for i,file in enumerate(data_list):\n",
    "    if ((last-limit) < targets[file] < (last+limit)) == False :\n",
    "        list_for_this.append(targets[file])\n",
    "        list_to_save.append(file)\n",
    "    last = targets[file]\n",
    "\n",
    "array_binned = np.round((np.array(list_for_this)/0.9)*100)\n",
    "print(np.size(array_binned))\n",
    "\n",
    "bins = np.linspace(0,100,100)\n",
    "plt.hist(array_binned,bins)\n",
    "plt.show()\n",
    "#draw 200 from 0, 3000 from 1-25, 200 from 25 to 0.35, 25 from 0.35 to end. gives me ~ 77,000 training examples (enough??)\n",
    "np.save('..\\\\misc\\\\train_data_uniform_in_Z.npy',np.array(list_to_save))\n",
    "\"\"\"\n",
    "train_list = np.load('..\\\\misc\\\\train_data_uniform_in_Z.npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(len(training_list)): #now get rid of the training data in our data_list\n",
    "    data_list.remove(training_list[i])\n",
    "\n",
    "print(len(data_list))\n",
    "\n",
    "#that took a while:\n",
    "np.save('..\\\\misc\\\\val_and_test_data_uniform_in_Z.npy',data_list)\n",
    "\"\"\"\n",
    "data_list = np.load('..\\\\misc\\\\val_and_test_data_uniform_in_Z.npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "random.shuffle(data_list)\n",
    "index_one = int(len(data_list)/3)\n",
    "val_list = data_list[0:index_one]\n",
    "test_list = data_list[index_one::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {'train':train_list,'validation':val_list,'test':test_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n",
      "72\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "#how many steps are in an epoch?\n",
    "steps_to_take = int(len(train_list)/batch_size)\n",
    "val_steps_to_take = int(len(val_list)/batch_size)\n",
    "test_steps_to_take = int(len(test_list)/batch_size)\n",
    "\n",
    "                #typically be equal to the number of unique samples if your dataset\n",
    "                #divided by the batch size.\n",
    "\n",
    "print(steps_to_take)\n",
    "print(val_steps_to_take)\n",
    "print(test_steps_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], targets, **params_train) #we want to shuffle these inputs\n",
    "validation_generator = DataGenerator(partition['validation'], targets, **params_test) #but not the val or test; need order for\n",
    "test_generator = DataGenerator(partition['test'], targets, **params_test)#analysis; shouldn't matter 'cause not training on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model set-up, callbacks</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so this is pretty neat, you can create a keras callback to display on tensorboard using a simplified summary tf api\n",
    "\n",
    "#and also this is an example of how to change the lr on the fly, which is pretty handy\n",
    "#https://keras.io/callbacks/\n",
    "\n",
    "\n",
    "def lr_schedule(epoch,lr):\n",
    "\n",
    "#Returns a custom learning rate that decreases as epochs progress.\n",
    "    if epoch > 1:\n",
    "        lr = 1e-5\n",
    "    if epoch > 2:\n",
    "        lr = 1e-6\n",
    "    if epoch > 3:\n",
    "        lr = 5e-7\n",
    "    if epoch > 4:\n",
    "        lr = 1e-7\n",
    "\n",
    "    tf.summary.scalar('learning_rate', tensor=lr)\n",
    "    return lr\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "#logdir=\"summaries/scalars/\" + str(datetime.datetime.now().timestamp())\n",
    "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "#                                                   histogram_freq=1,\n",
    "#                                                   write_graph=False,\n",
    "#                                                   write_grads=True,)\n",
    "#                                                   #write_images=True)\n",
    "#will it still print stuff\n",
    "\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1,\n",
    "#                             patience=2, min_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef create_model(learning_rate=learning_rate):\\n    \\n    model = keras.Sequential([])\\n    model.add(keras.layers.Dense(input_shape=(13,),units=13,activation=keras.activations.linear))\\n    #model.add(keras.layers.Dropout(rate=0.25))\\n    #model.add(keras.layers.Dense(units=6,activation=keras.activations.linear))\\n    model.add(keras.layers.Dropout(rate=0.25))\\n    #model.add(keras.layers.Dense(units=6,activation=keras.activations.linear))\\n    #model.add(keras.layers.Dropout(rate=0.25))\\n    #model.add(keras.layers.Dense(units=6,activation=keras.activations.linear)) #tf.nn.relu\\n    #model.add(keras.layers.Dropout(rate=0.25))\\n    model.add(keras.layers.Dense(units=params_train['n_classes'],activation=keras.activations.linear))\\n    #RMS = keras.optimizers.RMSprop(learning_rate=learning_rate)\\n    adam = keras.optimizers.Adam(lr=learning_rate, clipnorm=0.1)\\n    model.compile(optimizer=adam, loss=keras.losses.logcosh) \\n    return(model)\\n\""
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def create_model(learning_rate=learning_rate):\n",
    "    \n",
    "    model = keras.Sequential([])\n",
    "    model.add(keras.layers.Dense(input_shape=(13,),units=13,activation=keras.activations.linear))\n",
    "    #model.add(keras.layers.Dropout(rate=0.25))\n",
    "    #model.add(keras.layers.Dense(units=6,activation=keras.activations.linear))\n",
    "    model.add(keras.layers.Dropout(rate=0.25))\n",
    "    #model.add(keras.layers.Dense(units=6,activation=keras.activations.linear))\n",
    "    #model.add(keras.layers.Dropout(rate=0.25))\n",
    "    #model.add(keras.layers.Dense(units=6,activation=keras.activations.linear)) #tf.nn.relu\n",
    "    #model.add(keras.layers.Dropout(rate=0.25))\n",
    "    model.add(keras.layers.Dense(units=params_train['n_classes'],activation=keras.activations.linear))\n",
    "    #RMS = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    adam = keras.optimizers.Adam(lr=learning_rate, clipnorm=0.1)\n",
    "    model.compile(optimizer=adam, loss=keras.losses.logcosh) \n",
    "    return(model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(learning_rate=learning_rate):\n",
    "    \n",
    "    model = keras.Sequential([])\n",
    "    model.add(keras.layers.Dense(input_shape=(13,),units=13,activation=keras.activations.linear))\n",
    "    model.add(keras.layers.Dropout(rate=0.15))\n",
    "    model.add(keras.layers.Dense(units=6,activation=keras.activations.linear))\n",
    "    model.add(keras.layers.Dropout(rate=0.15))\n",
    "    model.add(keras.layers.Dense(units=6,activation=keras.activations.linear))\n",
    "    model.add(keras.layers.Dropout(rate=0.15))\n",
    "    model.add(keras.layers.Dense(units=6,activation=keras.activations.linear)) #tf.nn.relu\n",
    "    model.add(keras.layers.Dropout(rate=0.15))\n",
    "    model.add(keras.layers.Dense(units=params_train['n_classes'],activation=keras.activations.linear))\n",
    "    \n",
    "    #RMS = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=adam, loss=keras.losses.mse) \n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"..\\\\saved_models\\\\DNN_MLP_10_11_19.hdf5\"\n",
    "#ModelCheckpointCB = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "ModelCheckpointCB = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = create_model(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "72/72 [==============================] - 381s 5s/step - loss: 6.6005\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.60051, saving model to ..\\saved_models\\DNN_MLP_10_11_19.hdf5\n",
      "231/231 [==============================] - 1236s 5s/step - loss: 100.3918 - val_loss: 6.6005\n",
      "Epoch 2/5\n",
      "72/72 [==============================] - 375s 5s/step - loss: 1.3537\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.60051 to 1.35371, saving model to ..\\saved_models\\DNN_MLP_10_11_19.hdf5\n",
      "231/231 [==============================] - 1453s 6s/step - loss: 40.4469 - val_loss: 1.3537\n",
      "Epoch 3/5\n",
      "72/72 [==============================] - 376s 5s/step - loss: 1.1828\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.35371 to 1.18275, saving model to ..\\saved_models\\DNN_MLP_10_11_19.hdf5\n",
      "231/231 [==============================] - 1433s 6s/step - loss: 30.3903 - val_loss: 1.1828\n",
      "Epoch 4/5\n",
      "72/72 [==============================] - 467s 6s/step - loss: 1.1637\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.18275 to 1.16370, saving model to ..\\saved_models\\DNN_MLP_10_11_19.hdf5\n",
      "231/231 [==============================] - 1502s 7s/step - loss: 29.4457 - val_loss: 1.1637\n",
      "Epoch 5/5\n",
      "72/72 [==============================] - 373s 5s/step - loss: 1.1529\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16370 to 1.15290, saving model to ..\\saved_models\\DNN_MLP_10_11_19.hdf5\n",
      "231/231 [==============================] - 1516s 7s/step - loss: 29.0092 - val_loss: 1.1529\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=epoch_number,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps_to_take,\n",
    "                    initial_epoch=0,\n",
    "                    verbose=1,\n",
    "                    callbacks=[ModelCheckpointCB,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data from the model ...10_10_19...\n",
    "\"\"\"\n",
    "\n",
    "Epoch 1/5\n",
    "923/924 [============================>.] - ETA: 3s - loss: 13.0287\n",
    "Epoch 00001: val_loss improved from inf to 0.01048, saving model to ..\\saved_models\\spectro_DNN_10_10_19.hdf5\n",
    "924/924 [==============================] - 3647s 4s/step - loss: 13.0147 - val_loss: 0.0105\n",
    "Epoch 2/5\n",
    "923/924 [============================>.] - ETA: 2s - loss: 0.0105\n",
    "Epoch 00002: val_loss improved from 0.01048 to 0.00002, saving model to ..\\saved_models\\spectro_DNN_10_10_19.hdf5\n",
    "924/924 [==============================] - 2714s 3s/step - loss: 0.0104 - val_loss: 1.7160e-05\n",
    "Epoch 3/5\n",
    "923/924 [============================>.] - ETA: 33s - loss: 0.0053 \n",
    "Epoch 00003: val_loss improved from 0.00002 to 0.00000, saving model to ..\\saved_models\\spectro_DNN_10_10_19.hdf5\n",
    "924/924 [==============================] - 31743s 34s/step - loss: 0.0053 - val_loss: 1.5744e-06\n",
    "Epoch 4/5\n",
    "923/924 [============================>.] - ETA: 2s - loss: 0.0040\n",
    "Epoch 00004: val_loss did not improve from 0.00000\n",
    "924/924 [==============================] - 2485s 3s/step - loss: 0.0040 - val_loss: 3.3565e-06\n",
    "Epoch 5/5\n",
    "923/924 [============================>.] - ETA: 3s - loss: 0.0038\n",
    "Epoch 00005: val_loss did not improve from 0.00000\n",
    "924/924 [==============================] - 4427s 5s/step - loss: 0.0038 - val_loss: 2.6210e-06\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source list\n",
    "\n",
    "Morphology:\n",
    "https://arxiv.org/pdf/1711.05744.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1807.00807.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1812.02183.pdf\n",
    "\n",
    "\n",
    "Coding sources:\n",
    "https://github.com/jameslawlor/kaggle_galaxy_zoo/blob/master/galaxy_zoo_keras.ipynb\n",
    "\n",
    "https://github.com/khanx169/DL_DES\n",
    "\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "\n",
    "\n",
    "this is where to download galaxies using SQL:\n",
    "http://skyserver.sdss.org/dr7/en/tools/search/sql.asp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ideas:\n",
    "\n",
    "implement the fair splitting function from scipy Gautham told you about\n",
    "\n",
    "Get better hardware to increase batchsize to something reasonable\n",
    "\n",
    "Get the morphological classifications into another directory, load them in the augmentation, becasuse we want to compare/make updates to the morphology section. because the R_90 takes up 12 spaces usually, last 6 can just be changed to the loaded in values easy. We want to use this to see if our morphological input helps at all, escpexially for low level regressors like this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 7s 93ms/step\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath)\n",
    "\n",
    "#model.evaluate_generator(generator=validation_generator,\n",
    "#                        steps=val_steps_to_take,\n",
    "#                        verbose=1)\n",
    "\n",
    "Val_pred = model.predict_generator(generator=validation_generator,\n",
    "    steps=val_steps_to_take,\n",
    "    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18432, 1)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(Val_pred))\n",
    "print(np.argmax(Val_pred))\n",
    "print(np.argmin(Val_pred))\n",
    "len(Val_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction bias (<z>) = -6.32151629983858\n",
      "Median absolute deviation (MAD) =  2.160406368704404\n",
      "outlier fraction (eta) = 0.04318576388888889\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import Spectro Redshift Labels\n",
    "#actually, these are our targets and are already imported under the variable name 'targets'\n",
    "\n",
    "X  = []\n",
    "Y = Val_pred[:,0]\n",
    "\"\"\" #only neccessary when we have multiple classes\n",
    "for i in range(len(Val_pred)):\n",
    "    Y[i] = np.where(Val_pred[i] == np.amax(Val_pred[i,1::]))[0] #first find where the maximum element is\n",
    "Y = Y*0.9/(n_classes -1) #next scale the results between 0 < 0.9\n",
    "\"\"\"\n",
    "\n",
    "if validation_generator.n_classes > 2:\n",
    "    new_Y = np.empty((len(validation_generator.list_IDs)))\n",
    "    for i in range(validation_generator.n_classes):\n",
    "        new_Y[i] = np.argmax(Y[i,:])\n",
    "    Y = (new_Y/validation_generator.n_classes)*0.4\n",
    "for label in validation_generator.list_IDs:\n",
    "    X.append(targets[label])\n",
    "    \n",
    "Y = np.array(Y)\n",
    "X = np.array(X)\n",
    "\n",
    "plt.plot(X[0:len(Y)],Y,'.',alpha=0.25)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('Spectro Z')\n",
    "plt.ylabel('Model Output PhotoZ')\n",
    "plt.title('Validation Set Results')\n",
    "\n",
    "#according to cohen et al 2000, we can evaluate our model using some better understood statistics invarient under N\n",
    "residuals = ((X[0:len(Y)] - Y)/ (1 + Y))\n",
    "prediction_bias = np.mean(residuals)\n",
    "MAD = 1.4826*np.median(abs(residuals - np.median(residuals))) #median absolute deviation\n",
    "outlier_fraction_eta = len(residuals[residuals > 5*MAD])/len(residuals)\n",
    "\n",
    "print('prediction bias (<z>) =', prediction_bias)\n",
    "print('Median absolute deviation (MAD) = ', MAD)\n",
    "print('outlier fraction (eta) =', outlier_fraction_eta)\n",
    "#plt.text(0.05,-0.18,'prediction bias (<z>) =' + str(round(prediction_bias,3)))\n",
    "#plt.text(0.05,-0.23,'Median absolute deviation (MAD) = ' + str(round(MAD,3)))\n",
    "#plt.text(0.05,-0.28,'outlier fraction (eta) = ' + str(round(outlier_fraction_eta,3)))\n",
    "\n",
    "\n",
    "#plt.text(0.1,0.8,'RMSE =' + str(round(RMSE,4)))\n",
    "plt.savefig('..\\\\outputs\\\\Validation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets are generated in a technical notebook, load them in here.\n",
    "with open(\"..\\\\misc\\\\Z_Photo.txt\",\"r\") as inf:\n",
    "    Photo_dict = eval(inf.read()) #is a dictionary that looks like: {alias:Photo_Z}\n",
    "    \n",
    "z_spectro = []\n",
    "z_photo = []\n",
    "for i in range(len(validation_generator.list_IDs)):\n",
    "    z_spectro.append(validation_generator.labels[validation_generator.list_IDs[i]])\n",
    "    if 0.0< validation_generator.labels[validation_generator.list_IDs[i]] < 1.0==False:\n",
    "        print('whoops: ',  validation_generator.labels[validation_generator.list_IDs[i]] )\n",
    "    z_photo.append(Photo_dict[validation_generator.list_IDs[i]])\n",
    "    \n",
    "Y = np.array(z_photo)\n",
    "X = np.array(z_spectro)\n",
    "\n",
    "plt.plot(X[0:len(Y)],Y,'.',alpha=0.25)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('Spectro Z')\n",
    "plt.ylabel('SDSS PhotoZ')\n",
    "plt.title('SDSS PhotoZ vs SpectroZ')\n",
    "\n",
    "#according to cohen et al 2000, we can evaluate our model using some better understood statistics invarient under N\n",
    "residuals = ((X[0:len(Y)] - Y)/ (1 + Y))\n",
    "prediction_bias = np.mean(residuals)\n",
    "MAD = 1.4826*np.median(abs(residuals - np.median(residuals))) #median absolute deviation\n",
    "outlier_fraction_eta = len(residuals[residuals > 5*MAD])/len(residuals)\n",
    "\n",
    "print('prediction bias (<z>) =', prediction_bias)\n",
    "print('Median absolute deviation (MAD) = ', MAD)\n",
    "print('outlier fraction (eta) =', outlier_fraction_eta)\n",
    "#plt.text(0.05,-0.18,'prediction bias (<z>) =' + str(round(prediction_bias,3)))\n",
    "#plt.text(0.05,-0.23,'Median absolute deviation (MAD) = ' + str(round(MAD,3)))\n",
    "#plt.text(0.05,-0.28,'outlier fraction (eta) = ' + str(round(outlier_fraction_eta,3)))\n",
    "\n",
    "plt.ylim(-0.01,0.4)\n",
    "plt.xlim(-0.01,0.4)\n",
    "#plt.text(0.1,0.8,'RMSE =' + str(round(RMSE,4)))\n",
    "plt.savefig('..\\\\outputs\\\\Original.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"..\\\\misc\\\\Z_Photo.txt\",\"r\") as inf:\n",
    "    Photo_dict = eval(inf.read()) #is a dictionary that looks like: {alias:Photo_Z}\n",
    "    \n",
    "z_spectro = []\n",
    "z_photo = []\n",
    "for i in range(len(training_generator.list_IDs)):\n",
    "    z_spectro.append(training_generator.labels[training_generator.list_IDs[i]])\n",
    "    if 0.0< training_generator.labels[training_generator.list_IDs[i]] < 1.0==False:\n",
    "        print('whoops: ',  training_generator.labels[training_generator.list_IDs[i]] )\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
