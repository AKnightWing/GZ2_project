{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "import os\n",
    "from skimage.transform import rotate\n",
    "import random\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import shift\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "#target_path = \"C:\\\\Users\\\\awe2\\\\DL_DES-master\\\\data\\\\sdss-galaxyzoo\\\\high_certainty\\\\sdss_metadata\\\\\"\n",
    "\n",
    "path = 'image_arrays_new_new_new\\\\'\n",
    "validation_path = path + 'test'\n",
    "training_path = path + 'training'\n",
    "\n",
    "#model variables\n",
    "batch_size = 32 #\n",
    "epoch_number = 50\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "params = {'dim': (64,64),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 5,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "#more parameters means more prone to overfitting, and I am 5/3 times worse on parameters compared to the paper I have\n",
    "#based this on. (5 bands instead of 3) I need to find ways to add more regularization, or otherwise might try reducing my number\n",
    "#of layers to reduce the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(120,120), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "     #   'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "    #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "    #'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "    # Initialization\n",
    "    \n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        X_resized = np.empty((self.batch_size, 120, 120, self.n_channels))\n",
    "      \n",
    "      # Generate data and perform augmentation\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "          # Store sample\n",
    "            X[i,] = np.load('image_arrays/' + ID + '.npy')\n",
    "                          \n",
    "            #flip\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],0)\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],1)\n",
    "            \n",
    "            #shift\n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (4,0,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (-4,0,0), mode='nearest')\n",
    "                              \n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,4,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,-4,0), mode='nearest')\n",
    "          \n",
    "            #zoom in/out\n",
    "            zoom_factor = random.uniform(0.75,1.3)\n",
    "            X[i,] = clipped_zoom(X[i,],zoom_factor)\n",
    "            \n",
    "            #rotate\n",
    "            angle = 45*random.random()\n",
    "            X[i,] = rotate(X[i,], angle=angle, mode='reflect')\n",
    "            \n",
    "            #resize\n",
    "            X_resized[i,] = resize(X[i,], (120,120,5) )\n",
    "            \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "    \n",
    "        if self.n_classes > 2:\n",
    "            return X_resized, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X_resized, y\n",
    "\n",
    "    def __len__(self):\n",
    "    #'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    #  'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "      # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv\", usecols=[8,15,21], nrows=10000)\n",
    "Class = galaxyzoo[\"gz2class\"].values\n",
    "dictionary = {'A':int(2),'E':np.array([0]),'S':np.array([1])}\n",
    "#resave using my dictionary\n",
    "target = np.empty((len(Class)))\n",
    "for i in range(len(Class)):\n",
    "    target[i] = dictionary[Class[i][0]]\n",
    "    \n",
    "spiral_debiased = galaxyzoo[\"t01_smooth_or_features_a02_features_or_disk_debiased\"].values\n",
    "elliptical_debiased = galaxyzoo[\"t01_smooth_or_features_a01_smooth_debiased\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = os.listdir(training_path)\n",
    "for i,file in enumerate(train_list):\n",
    "    train_list[i] = file.split('.')[0]\n",
    "val_list = os.listdir(validation_path)\n",
    "for i,file in enumerate(val_list):\n",
    "    val_list[i] = file.split('.')[0]\n",
    "\n",
    "partition = {'train':train_list,'validation':val_list}\n",
    "\n",
    "labels = {}\n",
    "for i in range(10000):\n",
    "    name = 'array_number_{}'.format(i)\n",
    "    labels.update({name:target[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate=learning_rate):\n",
    "    \n",
    "    model = keras.Sequential([])\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(input_shape=(120,120,5),filters=32,kernel_size=6,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=64,kernel_size=5,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "    model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=128,kernel_size=2,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "    model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "    \n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.35)) #best = 0.35\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=64,activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=1,activation=tf.nn.sigmoid)) #tf.nn.softmax for categorical, sigmoid for binary\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy',metrics=['accuracy']) \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = create_model(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"models\\\\5-band-CNN-correct-filters-little-more.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "steps_to_take = int(len(train_list)/batch_size)\n",
    "val_steps_to_take = int(len(val_list)/batch_size)\n",
    "                #typically be equal to the number of unique samples if your dataset\n",
    "                #divided by the batch size.\n",
    "print(steps_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 333s 1s/step - loss: 0.6756 - acc: 0.5924\n"
     ]
    }
   ],
   "source": [
    "hist2 = model.evaluate_generator(generator=validation_generator,\n",
    "                    steps=val_steps_to_take, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"models\\\\5-band-CNN-correct-filters-little-more.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:605: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n",
      "C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 120s 2s/step - loss: 0.6815 - acc: 0.5811\n",
      "Epoch 2/3\n",
      "79/79 [==============================] - 72s 911ms/step - loss: 0.6792 - acc: 0.5767\n",
      "Epoch 3/3\n",
      "79/79 [==============================] - 73s 920ms/step - loss: 0.6764 - acc: 0.5985\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=3,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 206s 897ms/step - loss: 0.6735 - acc: 0.5924\n"
     ]
    }
   ],
   "source": [
    "hist1 = model.evaluate_generator(generator=validation_generator,\n",
    "                    steps=val_steps_to_take, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"models\\\\5-band-CNN-correct-filters-little-more.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 72s 916ms/step - loss: 0.6832 - acc: 0.5807\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 72s 910ms/step - loss: 0.6795 - acc: 0.5866\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 72s 907ms/step - loss: 0.6802 - acc: 0.5748\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 72s 905ms/step - loss: 0.6707 - acc: 0.5941\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 72s 913ms/step - loss: 0.6629 - acc: 0.6290\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 72s 916ms/step - loss: 0.6323 - acc: 0.6487\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 72s 912ms/step - loss: 0.5626 - acc: 0.7409\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 72s 912ms/step - loss: 0.5347 - acc: 0.7694\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 73s 919ms/step - loss: 0.4885 - acc: 0.7805\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 72s 916ms/step - loss: 0.4947 - acc: 0.7789\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 72s 915ms/step - loss: 0.4628 - acc: 0.8034\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 72s 913ms/step - loss: 0.4293 - acc: 0.8129\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 72s 908ms/step - loss: 0.4501 - acc: 0.8046\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 72s 912ms/step - loss: 0.4245 - acc: 0.8089\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 72s 916ms/step - loss: 0.4431 - acc: 0.7979\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 72s 915ms/step - loss: 0.3991 - acc: 0.8212\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 72s 917ms/step - loss: 0.4004 - acc: 0.8220\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 72s 909ms/step - loss: 0.4193 - acc: 0.8097\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 72s 906ms/step - loss: 0.3905 - acc: 0.8244\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 72s 913ms/step - loss: 0.4170 - acc: 0.8133\n"
     ]
    }
   ],
   "source": [
    "hist4 = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 207s 900ms/step - loss: 0.4380 - acc: 0.7970\n"
     ]
    }
   ],
   "source": [
    "hist5 = model.evaluate_generator(generator=validation_generator,\n",
    "                    steps=val_steps_to_take, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"models\\\\5-band-CNN-correct-filters-little-more.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch,lr):\n",
    "\n",
    "#Returns a custom learning rate that decreases as epochs progress.\n",
    "    if epoch > 13:\n",
    "        lr = 1e-4\n",
    "    if epoch > 7:\n",
    "        lr = 1e-5\n",
    "    if epoch > 25:\n",
    "        lr = 1e-6\n",
    "    if epoch > 35:\n",
    "        lr = 1e-7\n",
    "\n",
    "    tf.summary.scalar('learning_rate', tensor=lr)\n",
    "    return lr\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 79s 1s/step - loss: 0.6865 - acc: 0.5799\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 74s 933ms/step - loss: 0.6802 - acc: 0.5819\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 73s 928ms/step - loss: 0.6631 - acc: 0.5965\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 73s 923ms/step - loss: 0.5813 - acc: 0.7049\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 74s 934ms/step - loss: 0.5281 - acc: 0.7504\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 74s 934ms/step - loss: 0.4714 - acc: 0.7809\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 72s 915ms/step - loss: 0.4747 - acc: 0.7686\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 72s 911ms/step - loss: 0.4565 - acc: 0.7959\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 72s 909ms/step - loss: 0.4232 - acc: 0.8058\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 72s 908ms/step - loss: 0.3944 - acc: 0.8323\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 72s 908ms/step - loss: 0.3993 - acc: 0.8157\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - 72s 908ms/step - loss: 0.3979 - acc: 0.8275\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 72s 915ms/step - loss: 0.4058 - acc: 0.8228\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 72s 910ms/step - loss: 0.3912 - acc: 0.8236\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - 72s 912ms/step - loss: 0.4018 - acc: 0.8180\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 72s 909ms/step - loss: 0.3935 - acc: 0.8236\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 74s 938ms/step - loss: 0.3964 - acc: 0.8311\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - 75s 953ms/step - loss: 0.3792 - acc: 0.8339\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 74s 940ms/step - loss: 0.4016 - acc: 0.8224\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 73s 925ms/step - loss: 0.4005 - acc: 0.8279\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - 73s 928ms/step - loss: 0.3915 - acc: 0.8208\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 74s 936ms/step - loss: 0.3951 - acc: 0.8354\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 75s 944ms/step - loss: 0.3813 - acc: 0.8374\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 74s 936ms/step - loss: 0.3873 - acc: 0.8240\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 74s 936ms/step - loss: 0.3885 - acc: 0.8299\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 74s 941ms/step - loss: 0.3835 - acc: 0.8378\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - 74s 938ms/step - loss: 0.4014 - acc: 0.8180\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 73s 928ms/step - loss: 0.3858 - acc: 0.8283\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 72s 914ms/step - loss: 0.3789 - acc: 0.8283\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - 73s 922ms/step - loss: 0.3975 - acc: 0.8275\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 72s 907ms/step - loss: 0.4033 - acc: 0.8220\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 72s 912ms/step - loss: 0.3847 - acc: 0.8287\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 73s 920ms/step - loss: 0.3878 - acc: 0.8283\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 72s 915ms/step - loss: 0.3834 - acc: 0.8339\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 72s 916ms/step - loss: 0.3846 - acc: 0.8267\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 73s 919ms/step - loss: 0.3768 - acc: 0.8299\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 73s 919ms/step - loss: 0.3844 - acc: 0.8295\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 73s 920ms/step - loss: 0.3779 - acc: 0.8295\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 72s 916ms/step - loss: 0.3873 - acc: 0.8267\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 72s 910ms/step - loss: 0.3803 - acc: 0.8279\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 72s 909ms/step - loss: 0.3958 - acc: 0.8275\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 72s 916ms/step - loss: 0.3808 - acc: 0.8343\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 72s 915ms/step - loss: 0.3900 - acc: 0.8279\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 73s 920ms/step - loss: 0.3717 - acc: 0.8386\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 73s 919ms/step - loss: 0.3906 - acc: 0.8200\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 72s 907ms/step - loss: 0.3877 - acc: 0.8307\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 72s 911ms/step - loss: 0.3828 - acc: 0.8323\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 72s 915ms/step - loss: 0.3758 - acc: 0.8323\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 74s 933ms/step - loss: 0.3754 - acc: 0.8382\n",
      "Epoch 50/50\n",
      "79/79 [==============================] - 74s 939ms/step - loss: 0.3926 - acc: 0.8267\n"
     ]
    }
   ],
   "source": [
    "hist4 = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    callbacks=[lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 253s 1s/step - loss: 0.4024 - acc: 0.8262\n"
     ]
    }
   ],
   "source": [
    "hist5 = model.evaluate_generator(generator=validation_generator,\n",
    "                    steps=val_steps_to_take, \n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
