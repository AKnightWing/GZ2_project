{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "import os\n",
    "import skimage\n",
    "import random\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import shift\n",
    "from keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "path = 'image_arrays_new_new\\\\'\n",
    "validation_path = path + 'validation'\n",
    "training_path = path + 'training'\n",
    "test_path = path + 'test'\n",
    "#model variables\n",
    "batch_size = 30 #\n",
    "epoch_number = 50\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "params = {'dim': (72,72),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "#more parameters means more prone to overfitting, and I am 5/3 times worse on parameters compared to the paper I have\n",
    "#based this on. (5 bands instead of 3) I need to find ways to add more regularization, or otherwise might try reducing my number\n",
    "#of layers to reduce the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(64,64), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "     #   'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "    #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "    #'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "    # Initialization\n",
    "\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels))\n",
    "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "      \n",
    "      # Generate data and perform augmentation\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "          # Store sample\n",
    "            #X[i,:,:,:] = np.load('image_arrays/' + ID + '.npy')[:,:,1:4]\n",
    "            X[i,4:68,4:68,:] = np.load('image_arrays/' + ID + '.npy')[:,:,1:4]              \n",
    "            #flip\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],0)\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],1)\n",
    "            \n",
    "            #shift\n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (4,0,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (-4,0,0), mode='nearest')\n",
    "                              \n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,4,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,-4,0), mode='nearest')\n",
    "          \n",
    "            #zoom in/out\n",
    "            zoom_factor = random.uniform(0.75,1.3)\n",
    "            X[i,] = clipped_zoom(X[i,],zoom_factor)\n",
    "            \n",
    "            #rotate\n",
    "            angle = 45*random.random()\n",
    "            X[i,] = skimage.transform.rotate(X[i,], angle=angle, mode='reflect')\n",
    "            \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "    \n",
    "        if self.n_classes > 2:\n",
    "            return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "    #'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    #  'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "      # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4099\n",
      "5887\n"
     ]
    }
   ],
   "source": [
    "galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv\", usecols=[8], nrows=10000)\n",
    "Class = galaxyzoo[\"gz2class\"].values\n",
    "dictionary = {'A':int(2),'E':np.array([0]),'S':np.array([1])}\n",
    "#resave using my dictionary\n",
    "target = np.empty((len(Class)))\n",
    "for i in range(len(Class)):\n",
    "    target[i] = dictionary[Class[i][0]]\n",
    "#target = target.astype(int)\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for i in target:\n",
    "    if i == np.array([0]):\n",
    "        count_0 += 1\n",
    "    if i == np.array([1]):\n",
    "        count_1 += 1\n",
    "\n",
    "print(count_0)\n",
    "print(count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = os.listdir(training_path)\n",
    "for i,file in enumerate(train_list):\n",
    "    train_list[i] = file.split('.')[0]\n",
    "val_list = os.listdir(validation_path)\n",
    "for i,file in enumerate(val_list):\n",
    "    val_list[i] = file.split('.')[0]\n",
    "\n",
    "partition = {'train':train_list,'validation':val_list}\n",
    "\n",
    "labels = {}\n",
    "for i in range(10000):\n",
    "    name = 'array_number_{}'.format(i)\n",
    "    labels.update({name:target[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so this is pretty neat, you can create a keras callback to display on tensorboard using a simplified summary tf api\n",
    "\n",
    "#and also this is an example of how to change the lr on the fly, which is pretty handy\n",
    "#https://keras.io/callbacks/\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "    file_writer.set_as_default()\n",
    "\"\"\"\n",
    "def lr_schedule(epoch,lr):\n",
    "\n",
    "#Returns a custom learning rate that decreases as epochs progress.\n",
    "    if epoch > 15:\n",
    "        lr = 1e-4\n",
    "    if epoch > 30:\n",
    "        lr = 1e-5\n",
    "\n",
    "    tf.summary.scalar('learning_rate', tensor=lr)\n",
    "    return lr\n",
    "\n",
    "#lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "logdir=\"summaries/scalars/\" + str(datetime.datetime.now().timestamp())\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "                                                   histogram_freq=1,\n",
    "                                                   write_graph=False,\n",
    "                                                   write_grads=True,)\n",
    "                                                   #write_images=True)\n",
    "#will it still print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbase_model = Xception(input_shape=(72,72,3), weights=\\'imagenet\\', include_top=False)\\nx = base_model.output\\nx = keras.layers.GlobalAveragePooling2D()(x)\\nx = keras.layers.Dense(1024, activation=\\'relu\\')(x)\\nx = keras.layers.Dropout(0.7)(x)\\nx = keras.layers.Dense(1024, activation=\"relu\", name=\\'second_last_layer\\')(x)\\npredictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\\n\\nmodel_final = Model(inputs=base_model.input, outputs=predictions)\\n\\nfor layer in base_model.layers:\\n    layer.trainable = False\\n\\nmodel_final.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "base_model = Xception(input_shape=(72,72,3), weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.7)(x)\n",
    "x = keras.layers.Dense(1024, activation=\"relu\", name='second_last_layer')(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_final = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_final.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "steps_to_take = int(len(os.listdir(training_path))/batch_size)\n",
    "val_steps_to_take = int(len(os.listdir(validation_path))/batch_size)\n",
    "                #typically be equal to the number of unique samples if your dataset\n",
    "                #divided by the batch size.\n",
    "\n",
    "print(steps_to_take)\n",
    "print(val_steps_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try it how we ran VGG16...\n",
    "\"\"\"\n",
    "Input_layer = layers.Input(shape=(32,32,3))\n",
    "base_model = vgg16.VGG16(include_top=False, weights='imagenet',input_tensor=Input_layer)\n",
    "\n",
    "x=base_model.output\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dropout(dropout)(x)\n",
    "x=layers.Dense(1024,activation='relu')(x)\n",
    "\"\"\"\n",
    "Input_layer = keras.layers.Input(shape=(72,72,3))\n",
    "base_model = keras.applications.Xception(input_tensor=Input_layer,weights='imagenet',include_top=False)\n",
    "\n",
    "x= base_model.output\n",
    "x= keras.layers.GlobalAveragePooling2D()(x)\n",
    "x= keras.layers.Dense(1024, activation=tf.nn.relu,name='first_dense')(x)\n",
    "x= keras.layers.Dropout(0.7)(x)\n",
    "x= keras.layers.Dense(1024, activation=tf.nn.relu,name='second_dense')(x)\n",
    "preds= keras.layers.Dense(1, activation=tf.nn.sigmoid,name='predictor')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d_8\n",
      "13 block2_pool\n",
      "14 batch_normalization_v1_8\n",
      "15 add_24\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_9\n",
      "23 block3_pool\n",
      "24 batch_normalization_v1_9\n",
      "25 add_25\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_10\n",
      "33 block4_pool\n",
      "34 batch_normalization_v1_10\n",
      "35 add_26\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_27\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_28\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_29\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_30\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_31\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_32\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_33\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_34\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_11\n",
      "123 block13_pool\n",
      "124 batch_normalization_v1_11\n",
      "125 add_35\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n",
      "132 global_average_pooling2d_2\n",
      "133 first_dense\n",
      "134 dropout_2\n",
      "135 second_dense\n",
      "136 predictor\n"
     ]
    }
   ],
   "source": [
    "#for i,layer in enumerate(model.layers):\n",
    "#    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:132]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[132:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkeras.backend.clear_session()\\ntf.reset_default_graph()\\n\\nbase_model = keras.applications.Xception(input_shape=(72,72,3),weights=\\'imagenet\\',include_top=False)\\n#base_model = keras.applications.Xception(weights=\\'imagenet\\',include_top=False)\\nfor layer in base_model.layers:\\n    layer.trainable = False\\n\\nmodel = keras.Sequential([])\\nmodel.add(keras.layers.InputLayer((72,72,3), name=\\'input\\'))\\nmodel.add(base_model)\\nmodel.add(keras.layers.GlobalAveragePooling2D(name=\\'global_after_transfer\\'))\\nmodel.add(keras.layers.Dense(1024, activation=tf.nn.relu,name=\\'first_dense\\'))\\nmodel.add(keras.layers.Dropout(0.7))\\nmodel.add(keras.layers.Dense(1024, activation=tf.nn.relu,name=\\'second_dense\\'))\\nmodel.add(keras.layers.Dense(1, activation=tf.nn.sigmoid,name=\\'predictor\\'))\\n\\nmodel.compile(loss=keras.losses.binary_crossentropy, optimizer = keras.optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nope this doesnt work\n",
    "\"\"\"\n",
    "keras.backend.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "base_model = keras.applications.Xception(input_shape=(72,72,3),weights='imagenet',include_top=False)\n",
    "#base_model = keras.applications.Xception(weights='imagenet',include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = keras.Sequential([])\n",
    "model.add(keras.layers.InputLayer((72,72,3), name='input'))\n",
    "model.add(base_model)\n",
    "model.add(keras.layers.GlobalAveragePooling2D(name='global_after_transfer'))\n",
    "model.add(keras.layers.Dense(1024, activation=tf.nn.relu,name='first_dense'))\n",
    "model.add(keras.layers.Dropout(0.7))\n",
    "model.add(keras.layers.Dense(1024, activation=tf.nn.relu,name='second_dense'))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid,name='predictor'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer = keras.optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'total_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-5834153c2f1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_steps_to_take\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                     verbose=2)\n\u001b[0m\u001b[0;32m      7\u001b[0m                     \u001b[1;31m#callbacks=[tensorboard_callback])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   batch_function = _make_execution_function(\n\u001b[1;32m--> 125\u001b[1;33m       model, mode, class_weight=class_weight)\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m   \u001b[1;31m# Create the queue for the generator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[1;34m(model, mode, class_weight)\u001b[0m\n\u001b[0;32m    425\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_fit_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1924\u001b[0m     ]\n\u001b[0;32m   1925\u001b[0m     self._make_train_function_helper(\n\u001b[1;32m-> 1926\u001b[1;33m         '_fit_function', [self.total_loss] + metrics_tensors)\n\u001b[0m\u001b[0;32m   1927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_updates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'total_loss'"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=1,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps_to_take,\n",
    "                    verbose=2,\n",
    "                    callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "#print('Test accuracy:', test_acc)\n",
    "#print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_prob = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source list\n",
    "\"\"\"\n",
    "https://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/\n",
    "\n",
    "https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "\n",
    "https://arxiv.org/pdf/1711.05744.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1807.00807.pdf\n",
    "\n",
    "https://github.com/jameslawlor/kaggle_galaxy_zoo/blob/master/galaxy_zoo_keras.ipynb\n",
    "\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "\n",
    "https://distill.pub/2018/building-blocks/ what I want to do with this after it is working.\n",
    "\n",
    "https://github.com/khanx169/DL_DES/blob/master/deeplearning/Xception_final.ipynb\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
