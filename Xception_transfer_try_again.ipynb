{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "import os\n",
    "import skimage\n",
    "import random\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import shift\n",
    "from keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "path = 'image_arrays_new_new\\\\'\n",
    "validation_path = path + 'validation'\n",
    "training_path = path + 'training'\n",
    "test_path = path + 'test'\n",
    "#model variables\n",
    "batch_size = 30 #\n",
    "epoch_number = 50\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "params = {'dim': (72,72),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "#more parameters means more prone to overfitting, and I am 5/3 times worse on parameters compared to the paper I have\n",
    "#based this on. (5 bands instead of 3) I need to find ways to add more regularization, or otherwise might try reducing my number\n",
    "#of layers to reduce the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(64,64), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "     #   'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "    #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "    #'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "    # Initialization\n",
    "\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels))\n",
    "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "      \n",
    "      # Generate data and perform augmentation\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "          # Store sample\n",
    "            #X[i,:,:,:] = np.load('image_arrays/' + ID + '.npy')[:,:,1:4]\n",
    "            X[i,4:68,4:68,:] = np.load('image_arrays/' + ID + '.npy')[:,:,1:4]              \n",
    "            #flip\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],0)\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],1)\n",
    "            \n",
    "            #shift\n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (4,0,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (-4,0,0), mode='nearest')\n",
    "                              \n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,4,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,-4,0), mode='nearest')\n",
    "          \n",
    "            #zoom in/out\n",
    "            zoom_factor = random.uniform(0.75,1.3)\n",
    "            X[i,] = clipped_zoom(X[i,],zoom_factor)\n",
    "            \n",
    "            #rotate\n",
    "            angle = 45*random.random()\n",
    "            X[i,] = skimage.transform.rotate(X[i,], angle=angle, mode='reflect')\n",
    "            \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "    \n",
    "        if self.n_classes > 2:\n",
    "            return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "    #'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    #  'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "      # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4099\n",
      "5887\n"
     ]
    }
   ],
   "source": [
    "galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv\", usecols=[8], nrows=10000)\n",
    "Class = galaxyzoo[\"gz2class\"].values\n",
    "dictionary = {'A':int(2),'E':np.array([0]),'S':np.array([1])}\n",
    "#resave using my dictionary\n",
    "target = np.empty((len(Class)))\n",
    "for i in range(len(Class)):\n",
    "    target[i] = dictionary[Class[i][0]]\n",
    "#target = target.astype(int)\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for i in target:\n",
    "    if i == np.array([0]):\n",
    "        count_0 += 1\n",
    "    if i == np.array([1]):\n",
    "        count_1 += 1\n",
    "\n",
    "print(count_0)\n",
    "print(count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = os.listdir(training_path)\n",
    "for i,file in enumerate(train_list):\n",
    "    train_list[i] = file.split('.')[0]\n",
    "val_list = os.listdir(validation_path)\n",
    "for i,file in enumerate(val_list):\n",
    "    val_list[i] = file.split('.')[0]\n",
    "\n",
    "partition = {'train':train_list,'validation':val_list}\n",
    "\n",
    "labels = {}\n",
    "for i in range(10000):\n",
    "    name = 'array_number_{}'.format(i)\n",
    "    labels.update({name:target[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so this is pretty neat, you can create a keras callback to display on tensorboard using a simplified summary tf api\n",
    "\n",
    "#and also this is an example of how to change the lr on the fly, which is pretty handy\n",
    "#https://keras.io/callbacks/\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "    file_writer.set_as_default()\n",
    "\"\"\"\n",
    "def lr_schedule(epoch,lr):\n",
    "\n",
    "#Returns a custom learning rate that decreases as epochs progress.\n",
    "    if epoch > 15:\n",
    "        lr = 1e-4\n",
    "    if epoch > 30:\n",
    "        lr = 1e-5\n",
    "\n",
    "    tf.summary.scalar('learning_rate', tensor=lr)\n",
    "    return lr\n",
    "\n",
    "#lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "logdir=\"summaries/scalars/\" + str(datetime.datetime.now().timestamp())\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "                                                   histogram_freq=1,\n",
    "                                                   write_graph=False,\n",
    "                                                   write_grads=True,)\n",
    "                                                   #write_images=True)\n",
    "#will it still print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbase_model = Xception(input_shape=(72,72,3), weights=\\'imagenet\\', include_top=False)\\nx = base_model.output\\nx = keras.layers.GlobalAveragePooling2D()(x)\\nx = keras.layers.Dense(1024, activation=\\'relu\\')(x)\\nx = keras.layers.Dropout(0.7)(x)\\nx = keras.layers.Dense(1024, activation=\"relu\", name=\\'second_last_layer\\')(x)\\npredictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\\n\\nmodel_final = Model(inputs=base_model.input, outputs=predictions)\\n\\nfor layer in base_model.layers:\\n    layer.trainable = False\\n\\nmodel_final.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "base_model = Xception(input_shape=(72,72,3), weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.7)(x)\n",
    "x = keras.layers.Dense(1024, activation=\"relu\", name='second_last_layer')(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_final = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_final.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "steps_to_take = int(len(os.listdir(training_path))/batch_size)\n",
    "val_steps_to_take = int(len(os.listdir(validation_path))/batch_size)\n",
    "                #typically be equal to the number of unique samples if your dataset\n",
    "                #divided by the batch size.\n",
    "\n",
    "print(steps_to_take)\n",
    "print(val_steps_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try it how we ran VGG16...\n",
    "\"\"\"\n",
    "Input_layer = layers.Input(shape=(32,32,3))\n",
    "base_model = vgg16.VGG16(include_top=False, weights='imagenet',input_tensor=Input_layer)\n",
    "\n",
    "x=base_model.output\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dropout(dropout)(x)\n",
    "x=layers.Dense(1024,activation='relu')(x)\n",
    "\"\"\"\n",
    "Input_layer = keras.layers.Input(shape=(72,72,3))\n",
    "base_model = keras.applications.Xception(input_tensor=Input_layer,weights='imagenet',include_top=False)\n",
    "\n",
    "x= base_model.output\n",
    "x= keras.layers.GlobalAveragePooling2D()(x)\n",
    "x= keras.layers.Dense(1024, activation=tf.nn.relu)(x)\n",
    "x= keras.layers.Dropout(0.7)(x)\n",
    "x= keras.layers.Dense(1024, activation=tf.nn.relu)(x)\n",
    "preds= keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,layer in enumerate(model.layers):\n",
    "#    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:132]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[132:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkeras.backend.clear_session()\\ntf.reset_default_graph()\\n\\nbase_model = keras.applications.Xception(input_shape=(72,72,3),weights=\\'imagenet\\',include_top=False)\\n#base_model = keras.applications.Xception(weights=\\'imagenet\\',include_top=False)\\nfor layer in base_model.layers:\\n    layer.trainable = False\\n\\nmodel = keras.Sequential([])\\nmodel.add(keras.layers.InputLayer((72,72,3), name=\\'input\\'))\\nmodel.add(base_model)\\nmodel.add(keras.layers.GlobalAveragePooling2D(name=\\'global_after_transfer\\'))\\nmodel.add(keras.layers.Dense(1024, activation=tf.nn.relu,name=\\'first_dense\\'))\\nmodel.add(keras.layers.Dropout(0.7))\\nmodel.add(keras.layers.Dense(1024, activation=tf.nn.relu,name=\\'second_dense\\'))\\nmodel.add(keras.layers.Dense(1, activation=tf.nn.sigmoid,name=\\'predictor\\'))\\n\\nmodel.compile(loss=keras.losses.binary_crossentropy, optimizer = keras.optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nope this doesnt work\n",
    "\"\"\"\n",
    "keras.backend.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "base_model = keras.applications.Xception(input_shape=(72,72,3),weights='imagenet',include_top=False)\n",
    "#base_model = keras.applications.Xception(weights='imagenet',include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = keras.Sequential([])\n",
    "model.add(keras.layers.InputLayer((72,72,3), name='input'))\n",
    "model.add(base_model)\n",
    "model.add(keras.layers.GlobalAveragePooling2D(name='global_after_transfer'))\n",
    "model.add(keras.layers.Dense(1024, activation=tf.nn.relu,name='first_dense'))\n",
    "model.add(keras.layers.Dropout(0.7))\n",
    "model.add(keras.layers.Dense(1024, activation=tf.nn.relu,name='second_dense'))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid,name='predictor'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer = keras.optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an optimizer, loss, and accuracy metric.\n",
    "adam = tf.keras.optimizers.Adam(1e-3)\n",
    "model.compile(optimizer=adam, loss=keras.losses.binary_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=1,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps_to_take,\n",
    "                    verbose=2,\n",
    "                    callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "#print('Test accuracy:', test_acc)\n",
    "#print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_prob = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source list\n",
    "\"\"\"\n",
    "https://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/\n",
    "\n",
    "https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "\n",
    "https://arxiv.org/pdf/1711.05744.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1807.00807.pdf\n",
    "\n",
    "https://github.com/jameslawlor/kaggle_galaxy_zoo/blob/master/galaxy_zoo_keras.ipynb\n",
    "\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "\n",
    "https://distill.pub/2018/building-blocks/ what I want to do with this after it is working.\n",
    "\n",
    "https://github.com/khanx169/DL_DES/blob/master/deeplearning/Xception_final.ipynb\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
