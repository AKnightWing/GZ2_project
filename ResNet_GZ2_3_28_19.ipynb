{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "processed_data = np.load('Full_array.npy')\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#The size of the dataset is 10,000; but I only filled the first 9166 with values, the rest are zeros. (shouldn't be counted)\n",
    "number = 9166\n",
    "processed_data = processed_data[0:number]\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to normalize our iamge data to go from 0 to 1\n",
    "processed_data = processed_data.reshape(np.size(processed_data))\n",
    "processed_data = (processed_data - min(processed_data))/ (max(processed_data) - min(processed_data))\n",
    "processed_data = processed_data.reshape(number,28,28)\n",
    "#I actually am not sure how it is scaled. however, some of the pixels are negative for some reason???\n",
    "\n",
    "#also, this did not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters:\n",
    "HP_allowed_confidence = 0.98\n",
    "test_train_split = 0.85\n",
    "batch_size = 64\n",
    "epoch_number = 5\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.3\n",
    "CNL1_filters = 32\n",
    "CNL1_kernal_size = 3\n",
    "MPL1_pool_size= (2,2)\n",
    "MPL1_strides = 2\n",
    "CNL2_filters = 64\n",
    "CNL2_kernal_size = 3\n",
    "MPL2_pool_size = (2,2)\n",
    "MPL2_strides = 2\n",
    "\n",
    "#I have a non-round number of examples\n",
    "train_split_indice = int(np.round(test_train_split*number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in my dataset of targets, targets are strings labels under the name \"Class\"\n",
    "galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv/zoo2MainSpecz.csv\", usecols=[2,3,4,8,15,21,27], nrows=number)\n",
    "#galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv/zoo2MainSpecz.csv\", nrows=number)\n",
    "Class = galaxyzoo[\"gz2class\"].values\n",
    "RA = galaxyzoo['ra'].values\n",
    "DEC = galaxyzoo['dec'].values\n",
    "Spiral = galaxyzoo['t01_smooth_or_features_a02_features_or_disk_debiased'].values\n",
    "Elliptical = galaxyzoo['t01_smooth_or_features_a01_smooth_debiased'].values\n",
    "Anythingelse = galaxyzoo['t01_smooth_or_features_a03_star_or_artifact_debiased'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to take the first character of the Class string and interpret as a integer, ala MNIST example code\n",
    "dictionary = {'A':int(2),'E':int(1),'S':int(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resave using my dictionary\n",
    "target = np.empty((len(Class)))\n",
    "for i in range(len(Class)):\n",
    "    target[i] = int(dictionary[Class[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through, find the arrays of zero, set that target to 'A' = 2\n",
    "for i in range(len(target)):\n",
    "    if processed_data[i].any() == 0:\n",
    "        target[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split my data between training and test sets\n",
    "train_target = target[0:train_split_indice]\n",
    "test_target = target[train_split_indice:number]\n",
    "train_images = processed_data[0:train_split_indice]\n",
    "test_images = processed_data[train_split_indice:number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31164,)\n",
      "(31164, 28, 28)\n",
      "31164\n",
      "(1375,)\n"
     ]
    }
   ],
   "source": [
    "#Create 3 more images from each of my training and testing images that is each image but flipped 90 degrees...\n",
    "train_images_flip1 = np.flip(train_images,1)\n",
    "train_images_flip2 = np.flip(train_images,2)\n",
    "train_images_flip3 = np.flip(train_images_flip1,2)\n",
    "\n",
    "flipped_img = np.append(train_images, train_images_flip1, 0)\n",
    "flipped_img = np.append(flipped_img, train_images_flip2, 0)\n",
    "flipped_img = np.append(flipped_img, train_images_flip3, 0)\n",
    "\n",
    "flipped_tar = np.append(train_target,train_target, 0)\n",
    "flipped_tar = np.append(flipped_tar,train_target, 0)\n",
    "flipped_tar = np.append(flipped_tar,train_target, 0)\n",
    "\n",
    "print(np.shape(flipped_tar))\n",
    "print(np.shape(flipped_img))\n",
    "print(np.size(train_target)*4)\n",
    "\n",
    "print(np.shape(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = flipped_img\n",
    "train_target = flipped_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#rotate each image in the target_images by a random amount\n",
    "rotations_array = np.empty((31164,28,28))\n",
    "for i in range(np.shape(train_images)[0]):\n",
    "    degree = np.random.uniform(-45,45,1)\n",
    "    img = Image.fromarray(train_images[i])\n",
    "    rot = img.rotate(degree)\n",
    "    rot = np.asarray(rot)\n",
    "    rotations_array[i] = rot\n",
    "#now append rotations_array to train_images\n",
    "train_images = np.append(train_images, rotations_array,0)\n",
    "#now append the class labels to the train_target array\n",
    "train_target = np.append(train_target,train_target)\n",
    "\n",
    "\n",
    "#every time we run this segment, we increase our training set by a factor of 2. this means it will train in 120 * number of times\n",
    "# times 20 epochs = a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_clipped_zoom(img, zoom_factor):\n",
    "    \"\"\"\n",
    "    Center zoom in/out of the given image and returning an enlarged/shrinked view of \n",
    "    the image without changing dimensions\n",
    "    Args:\n",
    "        img : Image array\n",
    "        zoom_factor : amount of zoom as a ratio (0 to Inf)\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2] # It's also the final desired shape\n",
    "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
    "\n",
    "    ### Crop only the part that will remain in the result (more efficient)\n",
    "    # Centered bbox of the final desired size in resized (larger/smaller) image coordinates\n",
    "    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n",
    "    y2, x2 = y1 + height, x1 + width\n",
    "    bbox = np.array([y1,x1,y2,x2])\n",
    "    # Map back to original image coordinates\n",
    "    bbox = (bbox / zoom_factor).astype(np.int)\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Handle padding when downscaling\n",
    "    resize_height, resize_width = min(new_height, height), min(new_width, width)\n",
    "    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n",
    "    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n",
    "    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n",
    "\n",
    "    result = resize(cropped_img, (resize_width, resize_height))\n",
    "    result = np.pad(result, pad_spec, mode='constant')\n",
    "    assert result.shape[0] == height and result.shape[1] == width\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase by a factor of two again, like above\n",
    "rotations_array = np.empty((31164*2,28,28))\n",
    "for i in range(np.shape(train_images)[0]):\n",
    "    degree = np.random.uniform(-45,45,1)\n",
    "    img = Image.fromarray(train_images[i])\n",
    "    rot = img.rotate(degree)\n",
    "    zoom_factor = np.random.uniform(0.7,1.3,1)\n",
    "    rot = cv2_clipped_zoom(np.asarray(rot),zoom_factor)\n",
    "    #rot = rot.resize()\n",
    "    #rot = np.asarray(rot)\n",
    "    rotations_array[i] = rot\n",
    "#now append rotations_array to train_images\n",
    "train_images = np.append(train_images, rotations_array,0)\n",
    "#now append the class labels to the train_target array\n",
    "train_target = np.append(train_target,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to form a subset of our training examples that are probabilities that they are sorted correctly greater than %90\n",
    "#we will then train this dataset additional times.\n",
    "train_images = train_images.reshape(train_split_indice*4*2*2,28,28,1)\n",
    "test_images = test_images.reshape((train_split_indice-number)*4*2*2,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "#X=[1,2,3]\n",
    "#y = ['one', 'two', 'three']\n",
    "#X, y = shuffle(X, y, random_state=0)\n",
    "#print(X)\n",
    "#print(y)\n",
    "train_images, train_target = shuffle(train_images, train_target, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, Conv2D, Add, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Found this function that defines a residual block to use in the sequential model. I like the sequential model. I will keep my\n",
    "#training wheels for now and learn functional API later.\n",
    "class Residual(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, channels_in,kernel,**kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        self.channels_in = channels_in\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def call(self, x):\n",
    "        # the residual block using Keras functional API\n",
    "        first_layer =   Activation(\"linear\", trainable=False)(x)\n",
    "        x =             Conv2D( self.channels_in,\n",
    "                                self.kernel,\n",
    "                                padding=\"same\")(first_layer)\n",
    "        x =             Activation(\"relu\")(x)\n",
    "        x =             Conv2D( self.channels_in,\n",
    "                                self.kernel,\n",
    "                                padding=\"same\")(x)\n",
    "        residual =      Add()([x, first_layer])\n",
    "        x =             Activation(\"relu\")(residual)\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "\n",
    "#call as model.add( Residual(32, (3,3) ))\n",
    "#residual layers replace convolutional layers. We get rid of dropout when using a res-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define my model, using a CNN with 2 Convolutional layers, 2 max pool layers, 1 dense layer, 1 drop out layer, and another dense layer \n",
    "def create_model(dropout_rate=dropout_rate, learning_rate=learning_rate):\n",
    "    model = keras.Sequential([])\n",
    "    model.add(keras.layers.Conv2D(input_shape=(28,28,1),filters=CNL1_filters,kernel_size=CNL1_kernal_size,\n",
    "                                  padding=\"same\",activation=tf.nn.relu))\n",
    "    model.add(Residual(32,(3,3)))\n",
    "    model.add(Residual(32,(3,3)))\n",
    "    model.add(Residual(32,(3,3)))\n",
    "    model.add(Residual(32,(3,3)))\n",
    "    #model.add(keras.layers.Conv2D(filters=128,kernel_size=CNL2_kernal_size,padding=\"same\",activation=tf.nn.relu))\n",
    "    #model.add(keras.layers.MaxPool2D(pool_size=MPL2_pool_size,strides=MPL2_strides))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=1024,activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "    model.add(keras.layers.Dense(units=3,activation=tf.nn.softmax))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_split = int(np.round(np.size(train_target)*0.90))\n",
    "#validation_images = train_images[validation_split::]\n",
    "#validation_target = train_target[validation_split::]\n",
    "#train_target = train_target[0:validation_split]\n",
    "#train_iamges = train_images[0:validation_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(dropout_rate=dropout_rate, learning_rate = learning_rate)\n",
    "\n",
    "model.load_weights(\"RES_NET_3_28_19.h5\")\n",
    "adam = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "124656/124656 [==============================] - 3007s 24ms/step - loss: 0.4314 - acc: 0.8074\n",
      "Epoch 2/3\n",
      "124656/124656 [==============================] - 2468s 20ms/step - loss: 0.4292 - acc: 0.8076\n",
      "Epoch 3/3\n",
      "124656/124656 [==============================] - 3233s 26ms/step - loss: 0.4254 - acc: 0.8108\n",
      "1375/1375 [==============================] - 12s 9ms/step\n",
      "Test accuracy: 0.8196363630728288\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_target, epochs=epoch_number, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "print('Test accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375/1375 [==============================] - 13s 9ms/step\n",
      "Test accuracy: 0.821818181254647\n"
     ]
    }
   ],
   "source": [
    "#model.summary()\n",
    "test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "#12 layers\n",
    "\n",
    "#0.808 after 10 epochs, typically, RESNETs get trained for a lot of epochs, like 50 - 100.\n",
    "\n",
    "#Implement transfer learning using exception? or any state of the art on imagenet. \n",
    "#I should search around and choose a state of the art with the minimum amount of parameters, (hard to train).\n",
    "#too few images is what professor Huerta describes as the problem, which is interesting to note."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
