{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "import os\n",
    "import skimage\n",
    "import random\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "path = 'image_arrays_new_new\\\\'\n",
    "validation_path = path + 'validation'\n",
    "training_path = path + 'training'\n",
    "test_path = path + 'test'\n",
    "#model variables\n",
    "batch_size = 30 #\n",
    "epoch_number = 75\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "params = {'dim': (64,64),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 5,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "#more parameters means more prone to overfitting, and I am 5/3 times worse on parameters compared to the paper I have\n",
    "#based this on. (5 bands instead of 3) I need to find ways to add more regularization, or otherwise might try reducing my number\n",
    "#of layers to reduce the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(64,64), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "     #   'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "    #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "    #'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "    # Initialization\n",
    "    \n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "    \n",
    "      \n",
    "      # Generate data and perform augmentation\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "          # Store sample\n",
    "            X[i,] = np.load('image_arrays/' + ID + '.npy')\n",
    "                          \n",
    "            #flip\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],0)\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],1)\n",
    "            \n",
    "            #shift\n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (4,0,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (-4,0,0), mode='nearest')\n",
    "                              \n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,4,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,-4,0), mode='nearest')\n",
    "          \n",
    "            #zoom in/out\n",
    "            zoom_factor = random.uniform(0.75,1.3)\n",
    "            X[i,] = clipped_zoom(X[i,],zoom_factor)\n",
    "            \n",
    "            #rotate\n",
    "            angle = 45*random.random()\n",
    "            X[i,] = skimage.transform.rotate(X[i,], angle=angle, mode='reflect')\n",
    "            \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "    \n",
    "        if self.n_classes > 2:\n",
    "            return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "    #'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    #  'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "      # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv\", usecols=[8,15,21], nrows=10000)\n",
    "Class = galaxyzoo[\"gz2class\"].values\n",
    "dictionary = {'A':int(2),'E':np.array([0]),'S':np.array([1])}\n",
    "#resave using my dictionary\n",
    "target = np.empty((len(Class)))\n",
    "for i in range(len(Class)):\n",
    "    target[i] = dictionary[Class[i][0]]\n",
    "    \n",
    "spiral_debiased = galaxyzoo[\"t01_smooth_or_features_a02_features_or_disk_debiased\"].values\n",
    "elliptical_debiased = galaxyzoo[\"t01_smooth_or_features_a01_smooth_debiased\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "1119\n"
     ]
    }
   ],
   "source": [
    "train_list = os.listdir(training_path)\n",
    "train_list_new = list()\n",
    "for i,file in enumerate(train_list):\n",
    "    if (spiral_debiased[i] > 0.95) or (elliptical_debiased[i] > 0.90):\n",
    "        train_list_new.append(file.split('.')[0])\n",
    "val_list = os.listdir(validation_path)\n",
    "val_list_new = list()\n",
    "for i,file in enumerate(val_list):\n",
    "    #if spiral_debiased[i] > 0.97 or elliptical_debiased[i] > 0.92:\n",
    "    val_list_new.append(file.split('.')[0])\n",
    "\n",
    "        \n",
    "partition = {'train':train_list_new,'validation':val_list_new}\n",
    "\n",
    "labels = {}\n",
    "for i in range(10000):\n",
    "    name = 'array_number_{}'.format(i)\n",
    "    labels.update({name:target[i]})\n",
    "    \n",
    "print(len(train_list_new))\n",
    "print(len(val_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so this is pretty neat, you can create a keras callback to display on tensorboard using a simplified summary tf api\n",
    "\n",
    "#and also this is an example of how to change the lr on the fly, which is pretty handy\n",
    "#https://keras.io/callbacks/\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "    file_writer.set_as_default()\n",
    "\"\"\"\n",
    "def lr_schedule(epoch,lr):\n",
    "\n",
    "#Returns a custom learning rate that decreases as epochs progress.\n",
    "    if epoch > 15:\n",
    "        lr = 1e-4\n",
    "    if epoch > 30:\n",
    "        lr = 1e-5\n",
    "\n",
    "    tf.summary.scalar('learning_rate', tensor=lr)\n",
    "    return lr\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "logdir=\"summaries/scalars/\" + str(datetime.datetime.now().timestamp())\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "                                                   histogram_freq=1,\n",
    "                                                   write_graph=False,\n",
    "                                                   write_grads=True,)\n",
    "                                                   #write_images=True)\n",
    "#will it still print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate=learning_rate):\n",
    "    \n",
    "    model = keras.Sequential([])\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(input_shape=(64,64,5),filters=32,kernel_size=6,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=64,kernel_size=5,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "    model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=128,kernel_size=2,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "    model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "    \n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.25)) #best = 0.35\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=64,activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=1,activation=tf.nn.sigmoid)) #tf.nn.softmax for categorical, sigmoid for binary\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy',metrics=['accuracy']) \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "model = create_model(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "steps_to_take = int(len(os.listdir(training_path))/batch_size /6)\n",
    "val_steps_to_take = int(len(os.listdir(validation_path))/batch_size)\n",
    "                #typically be equal to the number of unique samples if your dataset\n",
    "                #divided by the batch size.\n",
    "\n",
    "print(steps_to_take)\n",
    "print(val_steps_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another callback\n",
    "#reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-8, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:605: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "37/37 [==============================] - 77s 2s/step - loss: 0.6642 - acc: 0.6153\n",
      " - 194s - loss: 0.6975 - acc: 0.5527 - val_loss: 0.6642 - val_acc: 0.6153\n",
      "Epoch 2/75\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.6463 - acc: 0.6216\n",
      " - 118s - loss: 0.6782 - acc: 0.5753 - val_loss: 0.6463 - val_acc: 0.6216\n",
      "Epoch 3/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.6845 - acc: 0.6162\n",
      " - 120s - loss: 0.6419 - acc: 0.6253 - val_loss: 0.6845 - val_acc: 0.6162\n",
      "Epoch 4/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.5187 - acc: 0.7640\n",
      " - 117s - loss: 0.5926 - acc: 0.6892 - val_loss: 0.5187 - val_acc: 0.7640\n",
      "Epoch 5/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.5961 - acc: 0.6667\n",
      " - 118s - loss: 0.5634 - acc: 0.7285 - val_loss: 0.5961 - val_acc: 0.6667\n",
      "Epoch 6/75\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.5049 - acc: 0.7631\n",
      " - 121s - loss: 0.5571 - acc: 0.7355 - val_loss: 0.5049 - val_acc: 0.7631\n",
      "Epoch 7/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.4589 - acc: 0.8081\n",
      " - 119s - loss: 0.5196 - acc: 0.7602 - val_loss: 0.4589 - val_acc: 0.8081\n",
      "Epoch 8/75\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.4498 - acc: 0.8153\n",
      " - 117s - loss: 0.5144 - acc: 0.7651 - val_loss: 0.4498 - val_acc: 0.8153\n",
      "Epoch 9/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.4563 - acc: 0.8081\n",
      " - 119s - loss: 0.4719 - acc: 0.7995 - val_loss: 0.4563 - val_acc: 0.8081\n",
      "Epoch 10/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.6148 - acc: 0.6901\n",
      " - 118s - loss: 0.4626 - acc: 0.7995 - val_loss: 0.6148 - val_acc: 0.6901\n",
      "Epoch 11/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.4182 - acc: 0.8162\n",
      " - 118s - loss: 0.4790 - acc: 0.7844 - val_loss: 0.4182 - val_acc: 0.8162\n",
      "Epoch 12/75\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.4153 - acc: 0.8171\n",
      " - 117s - loss: 0.4552 - acc: 0.8065 - val_loss: 0.4153 - val_acc: 0.8171\n",
      "Epoch 13/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.4273 - acc: 0.8162\n",
      " - 118s - loss: 0.4373 - acc: 0.8188 - val_loss: 0.4273 - val_acc: 0.8162\n",
      "Epoch 14/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.4140 - acc: 0.8144\n",
      " - 118s - loss: 0.4477 - acc: 0.7914 - val_loss: 0.4140 - val_acc: 0.8144\n",
      "Epoch 15/75\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.4107 - acc: 0.8306\n",
      " - 117s - loss: 0.4384 - acc: 0.8118 - val_loss: 0.4107 - val_acc: 0.8306\n",
      "Epoch 16/75\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.3936 - acc: 0.8360\n",
      " - 117s - loss: 0.4284 - acc: 0.8263 - val_loss: 0.3936 - val_acc: 0.8360\n",
      "Epoch 17/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3944 - acc: 0.8243\n",
      " - 118s - loss: 0.4103 - acc: 0.8296 - val_loss: 0.3944 - val_acc: 0.8243\n",
      "Epoch 18/75\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.4387 - acc: 0.8009\n",
      " - 117s - loss: 0.4059 - acc: 0.8301 - val_loss: 0.4387 - val_acc: 0.8009\n",
      "Epoch 19/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.4023 - acc: 0.8288\n",
      " - 118s - loss: 0.4053 - acc: 0.8242 - val_loss: 0.4023 - val_acc: 0.8288\n",
      "Epoch 20/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3814 - acc: 0.8315\n",
      " - 118s - loss: 0.3916 - acc: 0.8317 - val_loss: 0.3814 - val_acc: 0.8315\n",
      "Epoch 21/75\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.3916 - acc: 0.8252\n",
      " - 121s - loss: 0.3924 - acc: 0.8301 - val_loss: 0.3916 - val_acc: 0.8252\n",
      "Epoch 22/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.4063 - acc: 0.8369\n",
      " - 119s - loss: 0.4026 - acc: 0.8253 - val_loss: 0.4063 - val_acc: 0.8369\n",
      "Epoch 23/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.4015 - acc: 0.8225\n",
      " - 122s - loss: 0.4044 - acc: 0.8301 - val_loss: 0.4015 - val_acc: 0.8225\n",
      "Epoch 24/75\n",
      "37/37 [==============================] - 53s 1s/step - loss: 0.3917 - acc: 0.8279\n",
      " - 128s - loss: 0.3847 - acc: 0.8312 - val_loss: 0.3917 - val_acc: 0.8279\n",
      "Epoch 25/75\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.3976 - acc: 0.8306\n",
      " - 122s - loss: 0.4018 - acc: 0.8269 - val_loss: 0.3976 - val_acc: 0.8306\n",
      "Epoch 26/75\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.3809 - acc: 0.8360\n",
      " - 123s - loss: 0.3873 - acc: 0.8376 - val_loss: 0.3809 - val_acc: 0.8360\n",
      "Epoch 27/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3853 - acc: 0.8279\n",
      " - 120s - loss: 0.3890 - acc: 0.8280 - val_loss: 0.3853 - val_acc: 0.8279\n",
      "Epoch 28/75\n",
      "37/37 [==============================] - 55s 1s/step - loss: 0.3915 - acc: 0.8315\n",
      " - 130s - loss: 0.3880 - acc: 0.8280 - val_loss: 0.3915 - val_acc: 0.8315\n",
      "Epoch 29/75\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.3806 - acc: 0.8324\n",
      " - 131s - loss: 0.3796 - acc: 0.8360 - val_loss: 0.3806 - val_acc: 0.8324\n",
      "Epoch 30/75\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.3863 - acc: 0.8234\n",
      " - 132s - loss: 0.3960 - acc: 0.8285 - val_loss: 0.3863 - val_acc: 0.8234\n",
      "Epoch 31/75\n",
      "37/37 [==============================] - 57s 2s/step - loss: 0.3790 - acc: 0.8360\n",
      " - 137s - loss: 0.3859 - acc: 0.8349 - val_loss: 0.3790 - val_acc: 0.8360\n",
      "Epoch 32/75\n",
      "37/37 [==============================] - 56s 2s/step - loss: 0.3740 - acc: 0.8459\n",
      " - 134s - loss: 0.3990 - acc: 0.8188 - val_loss: 0.3740 - val_acc: 0.8459\n",
      "Epoch 33/75\n",
      "37/37 [==============================] - 68s 2s/step - loss: 0.3973 - acc: 0.8378\n",
      " - 164s - loss: 0.3848 - acc: 0.8285 - val_loss: 0.3973 - val_acc: 0.8378\n",
      "Epoch 34/75\n",
      "37/37 [==============================] - 53s 1s/step - loss: 0.3943 - acc: 0.8315\n",
      " - 134s - loss: 0.3810 - acc: 0.8403 - val_loss: 0.3943 - val_acc: 0.8315\n",
      "Epoch 35/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.4067 - acc: 0.8135\n",
      " - 123s - loss: 0.3786 - acc: 0.8457 - val_loss: 0.4067 - val_acc: 0.8135\n",
      "Epoch 36/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3736 - acc: 0.8459\n",
      " - 120s - loss: 0.4003 - acc: 0.8344 - val_loss: 0.3736 - val_acc: 0.8459\n",
      "Epoch 37/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3930 - acc: 0.8342\n",
      " - 120s - loss: 0.3791 - acc: 0.8446 - val_loss: 0.3930 - val_acc: 0.8342\n",
      "Epoch 38/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.4007 - acc: 0.8144\n",
      " - 121s - loss: 0.3778 - acc: 0.8387 - val_loss: 0.4007 - val_acc: 0.8144\n",
      "Epoch 39/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3851 - acc: 0.8342\n",
      " - 120s - loss: 0.3831 - acc: 0.8333 - val_loss: 0.3851 - val_acc: 0.8342\n",
      "Epoch 40/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3764 - acc: 0.8396\n",
      " - 119s - loss: 0.3721 - acc: 0.8414 - val_loss: 0.3764 - val_acc: 0.8396\n",
      "Epoch 41/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3926 - acc: 0.8261\n",
      " - 120s - loss: 0.3799 - acc: 0.8387 - val_loss: 0.3926 - val_acc: 0.8261\n",
      "Epoch 42/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3759 - acc: 0.8342\n",
      " - 120s - loss: 0.3902 - acc: 0.8398 - val_loss: 0.3759 - val_acc: 0.8342\n",
      "Epoch 43/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3975 - acc: 0.8324\n",
      " - 120s - loss: 0.3893 - acc: 0.8328 - val_loss: 0.3975 - val_acc: 0.8324\n",
      "Epoch 44/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3835 - acc: 0.8306\n",
      " - 119s - loss: 0.3863 - acc: 0.8355 - val_loss: 0.3835 - val_acc: 0.8306\n",
      "Epoch 45/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3784 - acc: 0.8360\n",
      " - 120s - loss: 0.3890 - acc: 0.8376 - val_loss: 0.3784 - val_acc: 0.8360\n",
      "Epoch 46/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3978 - acc: 0.8270\n",
      " - 121s - loss: 0.3929 - acc: 0.8349 - val_loss: 0.3978 - val_acc: 0.8270\n",
      "Epoch 47/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3891 - acc: 0.8297\n",
      " - 119s - loss: 0.3921 - acc: 0.8360 - val_loss: 0.3891 - val_acc: 0.8297\n",
      "Epoch 48/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3882 - acc: 0.8306\n",
      " - 120s - loss: 0.3675 - acc: 0.8500 - val_loss: 0.3882 - val_acc: 0.8306\n",
      "Epoch 49/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3847 - acc: 0.8198\n",
      " - 120s - loss: 0.3828 - acc: 0.8441 - val_loss: 0.3847 - val_acc: 0.8198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.4045 - acc: 0.8261\n",
      " - 120s - loss: 0.4012 - acc: 0.8371 - val_loss: 0.4045 - val_acc: 0.8261\n",
      "Epoch 51/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3895 - acc: 0.8270\n",
      " - 121s - loss: 0.3844 - acc: 0.8269 - val_loss: 0.3895 - val_acc: 0.8270\n",
      "Epoch 52/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3874 - acc: 0.8252\n",
      " - 120s - loss: 0.3963 - acc: 0.8285 - val_loss: 0.3874 - val_acc: 0.8252\n",
      "Epoch 53/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3878 - acc: 0.8351\n",
      " - 120s - loss: 0.3868 - acc: 0.8280 - val_loss: 0.3878 - val_acc: 0.8351\n",
      "Epoch 54/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3759 - acc: 0.8333\n",
      " - 119s - loss: 0.3706 - acc: 0.8468 - val_loss: 0.3759 - val_acc: 0.8333\n",
      "Epoch 55/75\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.3902 - acc: 0.8261\n",
      " - 121s - loss: 0.3853 - acc: 0.8403 - val_loss: 0.3902 - val_acc: 0.8261\n",
      "Epoch 56/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3857 - acc: 0.8306\n",
      " - 120s - loss: 0.3931 - acc: 0.8328 - val_loss: 0.3857 - val_acc: 0.8306\n",
      "Epoch 57/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3935 - acc: 0.8261\n",
      " - 122s - loss: 0.3723 - acc: 0.8522 - val_loss: 0.3935 - val_acc: 0.8261\n",
      "Epoch 58/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3913 - acc: 0.8324\n",
      " - 120s - loss: 0.3894 - acc: 0.8344 - val_loss: 0.3913 - val_acc: 0.8324\n",
      "Epoch 59/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3771 - acc: 0.8333\n",
      " - 120s - loss: 0.3981 - acc: 0.8333 - val_loss: 0.3771 - val_acc: 0.8333\n",
      "Epoch 60/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3702 - acc: 0.8324\n",
      " - 120s - loss: 0.3829 - acc: 0.8366 - val_loss: 0.3702 - val_acc: 0.8324\n",
      "Epoch 61/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3923 - acc: 0.8333\n",
      " - 120s - loss: 0.3970 - acc: 0.8274 - val_loss: 0.3923 - val_acc: 0.8333\n",
      "Epoch 62/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3776 - acc: 0.8324\n",
      " - 120s - loss: 0.3778 - acc: 0.8414 - val_loss: 0.3776 - val_acc: 0.8324\n",
      "Epoch 63/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3941 - acc: 0.8279\n",
      " - 121s - loss: 0.3775 - acc: 0.8344 - val_loss: 0.3941 - val_acc: 0.8279\n",
      "Epoch 64/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3871 - acc: 0.8342\n",
      " - 120s - loss: 0.3665 - acc: 0.8446 - val_loss: 0.3871 - val_acc: 0.8342\n",
      "Epoch 65/75\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.3956 - acc: 0.8297\n",
      " - 121s - loss: 0.3748 - acc: 0.8495 - val_loss: 0.3956 - val_acc: 0.8297\n",
      "Epoch 66/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3867 - acc: 0.8288\n",
      " - 120s - loss: 0.3767 - acc: 0.8392 - val_loss: 0.3867 - val_acc: 0.8288\n",
      "Epoch 67/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3975 - acc: 0.8279\n",
      " - 120s - loss: 0.3840 - acc: 0.8360 - val_loss: 0.3975 - val_acc: 0.8279\n",
      "Epoch 68/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3889 - acc: 0.8306\n",
      " - 120s - loss: 0.3791 - acc: 0.8419 - val_loss: 0.3889 - val_acc: 0.8306\n",
      "Epoch 69/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.4002 - acc: 0.8279\n",
      " - 121s - loss: 0.3765 - acc: 0.8344 - val_loss: 0.4002 - val_acc: 0.8279\n",
      "Epoch 70/75\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.3796 - acc: 0.8360\n",
      " - 119s - loss: 0.3924 - acc: 0.8312 - val_loss: 0.3796 - val_acc: 0.8360\n",
      "Epoch 71/75\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.4011 - acc: 0.8252\n",
      " - 121s - loss: 0.3845 - acc: 0.8419 - val_loss: 0.4011 - val_acc: 0.8252\n",
      "Epoch 72/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3982 - acc: 0.8297\n",
      " - 119s - loss: 0.3844 - acc: 0.8484 - val_loss: 0.3982 - val_acc: 0.8297\n",
      "Epoch 73/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3950 - acc: 0.8270\n",
      " - 121s - loss: 0.3783 - acc: 0.8387 - val_loss: 0.3950 - val_acc: 0.8270\n",
      "Epoch 74/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3929 - acc: 0.8342\n",
      " - 123s - loss: 0.3885 - acc: 0.8333 - val_loss: 0.3929 - val_acc: 0.8342\n",
      "Epoch 75/75\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.3909 - acc: 0.8270\n",
      " - 120s - loss: 0.3804 - acc: 0.8290 - val_loss: 0.3909 - val_acc: 0.8270\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=epoch_number,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps_to_take,\n",
    "                    verbose=2,\n",
    "                    callbacks=[tensorboard_callback,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "#print('Test accuracy:', test_acc)\n",
    "#print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_prob = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/\\n\\nhttps://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\\n\\nhttps://arxiv.org/pdf/1711.05744.pdf\\n\\nhttps://arxiv.org/pdf/1807.00807.pdf\\n\\nhttps://github.com/jameslawlor/kaggle_galaxy_zoo/blob/master/galaxy_zoo_keras.ipynb\\n\\nhttps://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\\n\\n#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\\n\\nhttps://distill.pub/2018/building-blocks/ what I want to do with this after it is working.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#source list\n",
    "\"\"\"\n",
    "https://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/\n",
    "\n",
    "https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "\n",
    "https://arxiv.org/pdf/1711.05744.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1807.00807.pdf\n",
    "\n",
    "https://github.com/jameslawlor/kaggle_galaxy_zoo/blob/master/galaxy_zoo_keras.ipynb\n",
    "\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "\n",
    "https://distill.pub/2018/building-blocks/ what I want to do with this after it is working.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-17-7db5de09873d>, line 157)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-7db5de09873d>\"\u001b[1;36m, line \u001b[1;32m157\u001b[0m\n\u001b[1;33m    _________________________________________________________________\u001b[0m\n\u001b[1;37m                                                                     \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "model_1:\n",
    "\n",
    "batch_size = 32 #\n",
    "epoch_number = 50\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "overfitted, but not unstable after 50 epochs unlike w/o augmentation.\n",
    "\n",
    "augments= flips, rotations\n",
    "\n",
    "tensorboard: 1561000349.947442\n",
    "\n",
    "architecture:\n",
    "model.add(keras.layers.Conv2D(input_shape=(64,64,5),filters=32,kernel_size=6,padding='same',activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64,kernel_size=5,padding='same',activation=tf.nn.relu))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=128,kernel_size=2,padding='same',activation=tf.nn.relu))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(rate=0.25)) #best = 0.35\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(units=64,activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(units=2,activation=tf.nn.softmax))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_2\n",
    "\n",
    "batch_size = 32 #\n",
    "epoch_number = 75\n",
    "learning_rate = 5e-4 \n",
    "\n",
    "same architecture as above\n",
    "\n",
    "tensorboard: 1561040263.807743\n",
    "\n",
    "premise: IDK lol just want something to run while I am working on my real job, but next time I think we will up dropouts,\n",
    "then decrease layers if that still tends to overfit\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_3 \n",
    "\n",
    "we get rid of the last convoluational layer, and increase all dropouts from 0.25 to 0.4\n",
    "\n",
    "else the same.\n",
    "\n",
    "Also, our steps to take was flipped from what they were meant to be; so we were training with very small epochs before.\n",
    "\n",
    "This means that our network does not train at the same speed, lol\n",
    "\n",
    "tensorboard = 1561056117.079296\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_4\n",
    "\n",
    "tried reducing LR to 1e-4, cut the number of filters in the third convolutional layer to 64, and increased dropout to 0.4 on all\n",
    "dropout = 0.25 layers. Newtwork accuracy did not increase, epoch accuracy convered lower than other attempts, newtork in general \n",
    "converged slower. BAD idea, maybe too little parameters. sweet spot might be in the middle somewhere. also did batch size => 64\n",
    "\n",
    "trying to fix network to make better use of the fact that we are in binary mode. , changed loss to binary_crossentropy, changed\n",
    "activation to sigmoid to match. reverted all other parameters to original archiecture, minus the fourth convolutional layer,\n",
    "which I have shown is unneccessary, I think. (incorrect, the best performing model was with that convolutional layer., lr=5e-4)\n",
    "\n",
    "tensorboard = 1561076766.823376\n",
    "\n",
    "Performs about as well as the model_2, we will keep the binary since that is what the paper we based off did.\n",
    "\n",
    "# params  = 2,334,817\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_5\n",
    "\n",
    "We introduce zooming in or out into our data augmentation, and we will introduce the last layer back into the model, since that\n",
    "was the best performing model.  Also am increasing dropout from 0.25 to 0.3 on layers, just to add a bit more regularization.\n",
    "\n",
    "Next thing I can add if this doesnt work is the moving of the center pixel around, and then after that we might consider\n",
    "increasing depth b/c I guess the best performing models have had more depth so far, but it is against intuition to do so.\n",
    "\n",
    "This performed wrose than model_2, which is disheartening because there was more augmentation. (hint, I maybe doing augmentat-\n",
    "ion wrong???)\n",
    "\n",
    "tensorboard=1561130093.100813\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_6\n",
    "\n",
    "Okay, eveything should be exactly the same as the paper we based off of. augmentations shifts of about 5% have been added, as\n",
    "as scaling of each channel to themselves. \"The flux values are normalised to the maximum value in each filter for each galaxy.\"\n",
    "\n",
    "I probably didnt need to waste time and just implement their result fully in the first place, but hey whatever I am learning\n",
    "\n",
    "Litteraly everything is the same as their paper except that we have (64,64) , we are not at the petrosian radius, and we have 5\n",
    "channels. So I will probably mess with architecure from here. I may start with increasring depth since it is one thing I havent\n",
    "tried yet.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_idk anymore lol\n",
    "\n",
    "tensorboard=scalars\\1561343515.138241\n",
    "\n",
    "added more layers, increased parameters. compared to model_2, the model didnt perform as well.\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              (None, 64, 64, 32)        5792      \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 64, 64, 64)        51264     \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 32, 32, 128)       32896     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 16, 16, 128)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 16, 16, 256)       131328    \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
    "_________________________________________________________________\n",
    "dropout_4 (Dropout)          (None, 8, 8, 512)         0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 32768)             0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 64)                2097216   \n",
    "_________________________________________________________________\n",
    "dropout_5 (Dropout)          (None, 64)                0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 1)                 65        \n",
    "=================================================================\n",
    "Total params: 3,498,721\n",
    "Trainable params: 3,498,721\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
