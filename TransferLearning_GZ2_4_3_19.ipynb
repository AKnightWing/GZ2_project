{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from __future__ import absolute_import, division, print_function\n",
    "\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "processed_data = np.load('Full_array.npy')\n",
    "Blue_processed_data = np.load('Blue_Full_array.npy')\n",
    "Red_processed_data = np.load(\"RED_Full_array.npy\")\n",
    "#The size of the dataset is 10,000; but I only filled the first 9166 with values, the rest are zeros. (shouldn't be counted)\n",
    "number = 9166\n",
    "processed_data = processed_data[0:number]\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from cv2 import resize\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to normalize our iamge data to go from 0 to 1\n",
    "#processed_data = processed_data.reshape(np.size(processed_data))\n",
    "#processed_data = (processed_data - min(processed_data))/ (max(processed_data) - min(processed_data))\n",
    "#processed_data = processed_data.reshape(number,28,28)\n",
    "#I actually am not sure how it is scaled. however, some of the pixels are negative for some reason???\n",
    "\n",
    "#also, this did not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters:\n",
    "test_train_split = 0.75\n",
    "batch_size = 64\n",
    "epoch_number = 50\n",
    "learning_rate = 1e-7\n",
    "validation_split = 0.10\n",
    "\n",
    "#I have a non-round number of examples\n",
    "train_split_indice = int(np.round(test_train_split*number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in my dataset of targets, targets are strings labels under the name \"Class\"\n",
    "galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv/zoo2MainSpecz.csv\", usecols=[2,3,4,8,15,21,27], nrows=number)\n",
    "#galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv/zoo2MainSpecz.csv\", nrows=number)\n",
    "Class = galaxyzoo[\"gz2class\"].values\n",
    "RA = galaxyzoo['ra'].values\n",
    "DEC = galaxyzoo['dec'].values\n",
    "#Spiral = galaxyzoo['t01_smooth_or_features_a02_features_or_disk_debiased'].values\n",
    "#Elliptical = galaxyzoo['t01_smooth_or_features_a01_smooth_debiased'].values\n",
    "#Anythingelse = galaxyzoo['t01_smooth_or_features_a03_star_or_artifact_debiased'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to take the first character of the Class string and interpret as a integer, ala MNIST example code\n",
    "dictionary = {'A':int(2),'E':int(1),'S':int(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resave using my dictionary\n",
    "target = np.empty((len(Class)))\n",
    "for i in range(len(Class)):\n",
    "    target[i] = int(dictionary[Class[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through, find the arrays of zero, set that target to 'A' = 2\n",
    "#for i in range(len(target)):\n",
    "#    if processed_data[i].any() == 0:\n",
    "#        target[i] = 2\n",
    "#    if Blue_processed_data[i].any() == 0:\n",
    "#        target[i] = 2\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split my data between training and test sets\n",
    "train_target = target[0:train_split_indice]\n",
    "test_target = target[train_split_indice:number]\n",
    "train_images = processed_data[0:train_split_indice]\n",
    "test_images = processed_data[train_split_indice:number]\n",
    "Blue_train_images = Blue_processed_data[0:train_split_indice]\n",
    "Blue_test_images = Blue_processed_data[train_split_indice::]\n",
    "Red_train_images = Red_processed_data[0:train_split_indice]\n",
    "Red_test_images = Red_processed_data[train_split_indice::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_images_flip1 = np.flip(train_images,1)\\ntrain_images_flip2 = np.flip(train_images,2)\\ntrain_images_flip3 = np.flip(train_images_flip1,2)\\n\\nflipped_img = np.append(train_images, train_images_flip1, 0)\\nflipped_img = np.append(flipped_img, train_images_flip2, 0)\\nflipped_img = np.append(flipped_img, train_images_flip3, 0)\\n\\nflipped_tar = np.append(train_target,train_target, 0)\\nflipped_tar = np.append(flipped_tar,train_target, 0)\\nflipped_tar = np.append(flipped_tar,train_target, 0)\\n\\nprint(np.shape(flipped_tar))\\nprint(np.shape(flipped_img))\\nprint(np.size(train_target)*4)\\n\\nprint(np.shape(test_target))\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create 3 more images from each of my training and testing images that is each image but flipped 90 degrees...\n",
    "\"\"\"\n",
    "train_images_flip1 = np.flip(train_images,1)\n",
    "train_images_flip2 = np.flip(train_images,2)\n",
    "train_images_flip3 = np.flip(train_images_flip1,2)\n",
    "\n",
    "flipped_img = np.append(train_images, train_images_flip1, 0)\n",
    "flipped_img = np.append(flipped_img, train_images_flip2, 0)\n",
    "flipped_img = np.append(flipped_img, train_images_flip3, 0)\n",
    "\n",
    "flipped_tar = np.append(train_target,train_target, 0)\n",
    "flipped_tar = np.append(flipped_tar,train_target, 0)\n",
    "flipped_tar = np.append(flipped_tar,train_target, 0)\n",
    "\n",
    "print(np.shape(flipped_tar))\n",
    "print(np.shape(flipped_img))\n",
    "print(np.size(train_target)*4)\n",
    "\n",
    "print(np.shape(test_target))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images = flipped_img\n",
    "#train_target = flipped_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#rotate each image in the target_images by a random amount\\nrotations_array = np.empty((31164,28,28))\\nfor i in range(np.shape(train_images)[0]):\\n    degree = np.random.uniform(-45,45,1)\\n    img = Image.fromarray(train_images[i])\\n    rot = img.rotate(degree)\\n    rot = np.asarray(rot)\\n    rotations_array[i] = rot\\n#now append rotations_array to train_images\\ntrain_images = np.append(train_images, rotations_array,0)\\n#now append the class labels to the train_target array\\ntrain_target = np.append(train_target,train_target)\\n\\n\\n#every time we run this segment, we increase our training set by a factor of 2. this means it will train in 120 * number of times\\n# times 20 epochs = a long time.\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#rotate each image in the target_images by a random amount\n",
    "rotations_array = np.empty((31164,28,28))\n",
    "for i in range(np.shape(train_images)[0]):\n",
    "    degree = np.random.uniform(-45,45,1)\n",
    "    img = Image.fromarray(train_images[i])\n",
    "    rot = img.rotate(degree)\n",
    "    rot = np.asarray(rot)\n",
    "    rotations_array[i] = rot\n",
    "#now append rotations_array to train_images\n",
    "train_images = np.append(train_images, rotations_array,0)\n",
    "#now append the class labels to the train_target array\n",
    "train_target = np.append(train_target,train_target)\n",
    "\n",
    "\n",
    "#every time we run this segment, we increase our training set by a factor of 2. this means it will train in 120 * number of times\n",
    "# times 20 epochs = a long time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_clipped_zoom(img, zoom_factor):\n",
    "    \"\"\"\n",
    "    Center zoom in/out of the given image and returning an enlarged/shrinked view of \n",
    "    the image without changing dimensions\n",
    "    Args:\n",
    "        img : Image array\n",
    "        zoom_factor : amount of zoom as a ratio (0 to Inf)\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2] # It's also the final desired shape\n",
    "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
    "\n",
    "    ### Crop only the part that will remain in the result (more efficient)\n",
    "    # Centered bbox of the final desired size in resized (larger/smaller) image coordinates\n",
    "    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n",
    "    y2, x2 = y1 + height, x1 + width\n",
    "    bbox = np.array([y1,x1,y2,x2])\n",
    "    # Map back to original image coordinates\n",
    "    bbox = (bbox / zoom_factor).astype(np.int)\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Handle padding when downscaling\n",
    "    resize_height, resize_width = min(new_height, height), min(new_width, width)\n",
    "    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n",
    "    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n",
    "    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n",
    "\n",
    "    result = resize(cropped_img, (resize_width, resize_height))\n",
    "    result = np.pad(result, pad_spec, mode='constant')\n",
    "    assert result.shape[0] == height and result.shape[1] == width\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#increase by a factor of two again, like above\\nrotations_array = np.empty((31164*2,28,28))\\nfor i in range(np.shape(train_images)[0]):\\n    degree = np.random.uniform(-45,45,1)\\n    img = Image.fromarray(train_images[i])\\n    rot = img.rotate(degree)\\n    zoom_factor = np.random.uniform(0.7,1.3,1)\\n    rot = cv2_clipped_zoom(np.asarray(rot),zoom_factor)\\n    #rot = rot.resize()\\n    #rot = np.asarray(rot)\\n    rotations_array[i] = rot\\n#now append rotations_array to train_images\\ntrain_images = np.append(train_images, rotations_array,0)\\n#now append the class labels to the train_target array\\ntrain_target = np.append(train_target,train_target)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#increase by a factor of two again, like above\n",
    "rotations_array = np.empty((31164*2,28,28))\n",
    "for i in range(np.shape(train_images)[0]):\n",
    "    degree = np.random.uniform(-45,45,1)\n",
    "    img = Image.fromarray(train_images[i])\n",
    "    rot = img.rotate(degree)\n",
    "    zoom_factor = np.random.uniform(0.7,1.3,1)\n",
    "    rot = cv2_clipped_zoom(np.asarray(rot),zoom_factor)\n",
    "    #rot = rot.resize()\n",
    "    #rot = np.asarray(rot)\n",
    "    rotations_array[i] = rot\n",
    "#now append rotations_array to train_images\n",
    "train_images = np.append(train_images, rotations_array,0)\n",
    "#now append the class labels to the train_target array\n",
    "train_target = np.append(train_target,train_target)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizes images to be 32x32 using cv2. my choice of model requires 32x32x3 images. I will have to add in the other channels as \n",
    "#copies\n",
    "\n",
    "import cv2 as cv2\n",
    "train_images_resized = np.empty((np.shape(train_images)[0],32,32))\n",
    "test_images_resized = np.empty((np.shape(test_images)[0],32,32))\n",
    "for i in range(np.shape(train_images)[0]):\n",
    "#img = cv2.imread(train_images[0])\n",
    "    train_images_resized[i] = resize(train_images[i], dsize=(32,32))\n",
    "for j in range(np.shape(test_images)[0]):\n",
    "    test_images_resized[j] = resize(test_images[j], dsize=(32,32))\n",
    "\n",
    "test_images = test_images_resized\n",
    "train_images = train_images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for the Blue_train_images and Blue_test_images\n",
    "train_images_resized = np.empty((np.shape(train_images)[0],32,32))\n",
    "test_images_resized = np.empty((np.shape(test_images)[0],32,32))\n",
    "for i in range(np.shape(Blue_train_images)[0]):\n",
    "#img = cv2.imread(train_images[0])\n",
    "    train_images_resized[i] = resize(Blue_train_images[i], dsize=(32,32))\n",
    "for j in range(np.shape(test_images)[0]):\n",
    "    test_images_resized[j] = resize(Blue_test_images[j], dsize=(32,32))\n",
    "\n",
    "Blue_test_images = test_images_resized\n",
    "Blue_train_images = train_images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for the Red_train_images and Red_test_images\n",
    "train_images_resized = np.empty((np.shape(train_images)[0],32,32))\n",
    "test_images_resized = np.empty((np.shape(test_images)[0],32,32))\n",
    "for i in range(np.shape(Red_train_images)[0]):\n",
    "#img = cv2.imread(train_images[0])\n",
    "    train_images_resized[i] = resize(Red_train_images[i], dsize=(32,32))\n",
    "for j in range(np.shape(test_images)[0]):\n",
    "    test_images_resized[j] = resize(Red_test_images[j], dsize=(32,32))\n",
    "\n",
    "Red_test_images = test_images_resized\n",
    "Red_train_images = train_images_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reform into the tensor shape\n",
    "train_images_number = np.shape(train_images)[0]\n",
    "test_images_number = np.shape(test_images)[0]\n",
    "train_images = train_images.reshape(train_images_number,32,32,1)\n",
    "test_images = test_images.reshape(test_images_number,32,32,1)\n",
    "Blue_train_images = Blue_train_images.reshape(train_images_number,32,32,1)\n",
    "Blue_test_images = Blue_test_images.reshape(test_images_number,32,32,1)\n",
    "Red_train_images = Red_train_images.reshape(train_images_number,32,32,1)\n",
    "Red_test_images = Red_test_images.reshape(test_images_number,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the order of the augmented images randomly, shuffle the order of the targets the same way.\n",
    "#train_images, train_target = shuffle(train_images, train_target, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6874, 32, 32, 1)\n",
      "(2292, 32, 32, 3)\n",
      "(6874, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#Seems I need to pad the arrays with zeros to get to 32x32, then copy the values of the first monochromatic channel into 3 channels\n",
    "#to use tranfer learning\n",
    "print(np.shape(train_images))\n",
    "\n",
    "train_images_middle_step = np.append(Red_train_images, train_images, 3)\n",
    "train_images = np.append(train_images_middle_step, Blue_train_images, 3)\n",
    "\n",
    "test_images_middle_step = np.append(Red_test_images,test_images, 3)\n",
    "test_images = np.append(test_images_middle_step,Blue_test_images, 3)\n",
    "\n",
    "print(np.shape(test_images))\n",
    "print(np.shape(train_images))\n",
    "\n",
    "#consider saving this array in the future instead of wasting time re-running the damn thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in and define my model, using transfer learning from a NN that was trained on image net\n",
    "#https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras import layers\n",
    "Input_layer = layers.Input(shape=(32,32,3))\n",
    "base_model = vgg16.VGG16(include_top=False, weights='imagenet',input_tensor=Input_layer)\n",
    "\n",
    "x=base_model.output\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dropout(0.40)(x)\n",
    "x=layers.Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "\n",
    "#x=layers.Dense(512,activation='relu')(x) #dense layer 2\n",
    "#x=layers.Dense(128,activation='relu')(x) #dense layer 3\n",
    "preds=layers.Dense(3,activation='softmax')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our model using the loaded base_model and our added layers\n",
    "from tensorflow.keras import Model\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n",
      "19 global_average_pooling2d_1\n",
      "20 dropout_1\n",
      "21 dense_2\n",
      "22 dense_3\n"
     ]
    }
   ],
   "source": [
    "#now that we have a model, we want to check the number of layers\n",
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the number of layers, we want to then tell the classifier to only train the new top layers, the dense layers we added\n",
    "#so that we maximize the benefit of the imagenet training.\n",
    "\n",
    "#for layer in model.layers:\n",
    "#    layer.trainable=False\n",
    "\n",
    "# or if we want to set the first 19 layers of the network to be non-trainable\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[15:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set up a validation and training set to tune hyperparameters.\n",
    "\n",
    "#validation_split = int(np.round(np.size(train_target)*0.90))\n",
    "#validation_images = train_images[validation_split::]\n",
    "#validation_target = train_target[validation_split::]\n",
    "#train_target = train_target[0:validation_split]\n",
    "#train_images = train_images[0:validation_split]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6874, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an optimizer, loss, and accuracy metric.\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndatagen = ImageDataGenerator(\\n    featurewise_center=True,\\n    featurewise_std_normalization=True,\\n    rotation_range=40,\\n    zoom_range=0.3,\\n    fill_mode='nearest'\\n    horizontal_flip=True,\\n    vetical_flip=True,\\n    data_format='channels_last',\\n    validation_split=validation_split)\\n\\ndatagen.fit(train_images)\\n\\nmodel.fit_generator(datagen.flow(train_images, train_targets, batch_size=batch_size),\\n                    steps_per_epoch=len(x_train) / batch_size, epochs=epoch_number)\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=40,\n",
    "    zoom_range=0.3,\n",
    "    fill_mode='nearest'\n",
    "    horizontal_flip=True,\n",
    "    vetical_flip=True,\n",
    "    data_format='channels_last',\n",
    "    validation_split=validation_split)\n",
    "\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images, train_targets, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train) / batch_size, epochs=epoch_number)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186 samples, validate on 688 samples\n",
      "Epoch 1/50\n",
      "6186/6186 [==============================] - 306s 50ms/sample - loss: 0.9630 - accuracy: 0.5949 - val_loss: 0.8794 - val_accuracy: 0.6366\n",
      "Epoch 2/50\n",
      "6186/6186 [==============================] - 277s 45ms/sample - loss: 0.9043 - accuracy: 0.6028 - val_loss: 0.8485 - val_accuracy: 0.6875\n",
      "Epoch 3/50\n",
      "6186/6186 [==============================] - 271s 44ms/sample - loss: 0.8573 - accuracy: 0.6269 - val_loss: 0.8259 - val_accuracy: 0.7035\n",
      "Epoch 4/50\n",
      "6186/6186 [==============================] - 273s 44ms/sample - loss: 0.8275 - accuracy: 0.6316 - val_loss: 0.8090 - val_accuracy: 0.7020\n",
      "Epoch 5/50\n",
      "6186/6186 [==============================] - 274s 44ms/sample - loss: 0.8064 - accuracy: 0.6372 - val_loss: 0.7950 - val_accuracy: 0.7064\n",
      "Epoch 6/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.7819 - accuracy: 0.6518 - val_loss: 0.7823 - val_accuracy: 0.6977\n",
      "Epoch 7/50\n",
      "6186/6186 [==============================] - 269s 43ms/sample - loss: 0.7780 - accuracy: 0.6429 - val_loss: 0.7711 - val_accuracy: 0.6860\n",
      "Epoch 8/50\n",
      "6186/6186 [==============================] - 265s 43ms/sample - loss: 0.7601 - accuracy: 0.6563 - val_loss: 0.7610 - val_accuracy: 0.6890\n",
      "Epoch 9/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.7426 - accuracy: 0.6610 - val_loss: 0.7509 - val_accuracy: 0.6846\n",
      "Epoch 10/50\n",
      "6186/6186 [==============================] - 282s 46ms/sample - loss: 0.7356 - accuracy: 0.6589 - val_loss: 0.7419 - val_accuracy: 0.6817\n",
      "Epoch 11/50\n",
      "6186/6186 [==============================] - 271s 44ms/sample - loss: 0.7266 - accuracy: 0.6686 - val_loss: 0.7333 - val_accuracy: 0.6831\n",
      "Epoch 12/50\n",
      "6186/6186 [==============================] - 275s 44ms/sample - loss: 0.7099 - accuracy: 0.6785 - val_loss: 0.7244 - val_accuracy: 0.6831\n",
      "Epoch 13/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.7069 - accuracy: 0.6781 - val_loss: 0.7164 - val_accuracy: 0.6846\n",
      "Epoch 14/50\n",
      "6186/6186 [==============================] - 271s 44ms/sample - loss: 0.7005 - accuracy: 0.6778 - val_loss: 0.7092 - val_accuracy: 0.6860\n",
      "Epoch 15/50\n",
      "6186/6186 [==============================] - 266s 43ms/sample - loss: 0.6956 - accuracy: 0.6754 - val_loss: 0.7023 - val_accuracy: 0.6904\n",
      "Epoch 16/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.6824 - accuracy: 0.6817 - val_loss: 0.6951 - val_accuracy: 0.6948\n",
      "Epoch 17/50\n",
      "6186/6186 [==============================] - 298s 48ms/sample - loss: 0.6829 - accuracy: 0.6846 - val_loss: 0.6885 - val_accuracy: 0.7035\n",
      "Epoch 18/50\n",
      "6186/6186 [==============================] - 276s 45ms/sample - loss: 0.6743 - accuracy: 0.6836 - val_loss: 0.6819 - val_accuracy: 0.7064\n",
      "Epoch 19/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.6675 - accuracy: 0.6859 - val_loss: 0.6755 - val_accuracy: 0.7078\n",
      "Epoch 20/50\n",
      "6186/6186 [==============================] - 266s 43ms/sample - loss: 0.6736 - accuracy: 0.6812 - val_loss: 0.6705 - val_accuracy: 0.7078\n",
      "Epoch 21/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.6544 - accuracy: 0.6929 - val_loss: 0.6657 - val_accuracy: 0.7093\n",
      "Epoch 22/50\n",
      "6186/6186 [==============================] - 267s 43ms/sample - loss: 0.6506 - accuracy: 0.6909 - val_loss: 0.6601 - val_accuracy: 0.7137\n",
      "Epoch 23/50\n",
      "6186/6186 [==============================] - 267s 43ms/sample - loss: 0.6450 - accuracy: 0.6929 - val_loss: 0.6547 - val_accuracy: 0.7151\n",
      "Epoch 24/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.6495 - accuracy: 0.6916 - val_loss: 0.6513 - val_accuracy: 0.7151\n",
      "Epoch 25/50\n",
      "6186/6186 [==============================] - 266s 43ms/sample - loss: 0.6469 - accuracy: 0.6916 - val_loss: 0.6476 - val_accuracy: 0.7137\n",
      "Epoch 26/50\n",
      "6186/6186 [==============================] - 267s 43ms/sample - loss: 0.6400 - accuracy: 0.6951 - val_loss: 0.6440 - val_accuracy: 0.7151\n",
      "Epoch 27/50\n",
      "6186/6186 [==============================] - 267s 43ms/sample - loss: 0.6309 - accuracy: 0.7022 - val_loss: 0.6399 - val_accuracy: 0.7137\n",
      "Epoch 28/50\n",
      "6186/6186 [==============================] - 267s 43ms/sample - loss: 0.6371 - accuracy: 0.6875 - val_loss: 0.6359 - val_accuracy: 0.7180\n",
      "Epoch 29/50\n",
      "6186/6186 [==============================] - 269s 43ms/sample - loss: 0.6323 - accuracy: 0.6964 - val_loss: 0.6329 - val_accuracy: 0.7180\n",
      "Epoch 30/50\n",
      "6186/6186 [==============================] - 267s 43ms/sample - loss: 0.6307 - accuracy: 0.6966 - val_loss: 0.6294 - val_accuracy: 0.7224\n",
      "Epoch 31/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.6244 - accuracy: 0.7022 - val_loss: 0.6269 - val_accuracy: 0.7224\n",
      "Epoch 32/50\n",
      "6186/6186 [==============================] - 267s 43ms/sample - loss: 0.6255 - accuracy: 0.6988 - val_loss: 0.6239 - val_accuracy: 0.7224\n",
      "Epoch 33/50\n",
      "6186/6186 [==============================] - 269s 44ms/sample - loss: 0.6187 - accuracy: 0.7032 - val_loss: 0.6214 - val_accuracy: 0.7267\n",
      "Epoch 34/50\n",
      "6186/6186 [==============================] - 272s 44ms/sample - loss: 0.6161 - accuracy: 0.6995 - val_loss: 0.6192 - val_accuracy: 0.7282\n",
      "Epoch 35/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.6098 - accuracy: 0.7048 - val_loss: 0.6170 - val_accuracy: 0.7282\n",
      "Epoch 36/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.6130 - accuracy: 0.7037 - val_loss: 0.6145 - val_accuracy: 0.7297\n",
      "Epoch 37/50\n",
      "6186/6186 [==============================] - 272s 44ms/sample - loss: 0.6082 - accuracy: 0.7064 - val_loss: 0.6118 - val_accuracy: 0.7297\n",
      "Epoch 38/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.6115 - accuracy: 0.7005 - val_loss: 0.6091 - val_accuracy: 0.7282\n",
      "Epoch 39/50\n",
      "6186/6186 [==============================] - 269s 43ms/sample - loss: 0.6106 - accuracy: 0.7003 - val_loss: 0.6078 - val_accuracy: 0.7326\n",
      "Epoch 40/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.6009 - accuracy: 0.7085 - val_loss: 0.6051 - val_accuracy: 0.7326\n",
      "Epoch 41/50\n",
      "6186/6186 [==============================] - 273s 44ms/sample - loss: 0.6034 - accuracy: 0.7124 - val_loss: 0.6032 - val_accuracy: 0.7340\n",
      "Epoch 42/50\n",
      "6186/6186 [==============================] - 272s 44ms/sample - loss: 0.6070 - accuracy: 0.7069 - val_loss: 0.6018 - val_accuracy: 0.7355\n",
      "Epoch 43/50\n",
      "6186/6186 [==============================] - 272s 44ms/sample - loss: 0.6074 - accuracy: 0.7082 - val_loss: 0.5994 - val_accuracy: 0.7355\n",
      "Epoch 44/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.5961 - accuracy: 0.7153 - val_loss: 0.5977 - val_accuracy: 0.7369\n",
      "Epoch 45/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.5965 - accuracy: 0.7103 - val_loss: 0.5959 - val_accuracy: 0.7355\n",
      "Epoch 46/50\n",
      "6186/6186 [==============================] - 269s 44ms/sample - loss: 0.6005 - accuracy: 0.7106 - val_loss: 0.5942 - val_accuracy: 0.7340\n",
      "Epoch 47/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.5930 - accuracy: 0.7106 - val_loss: 0.5927 - val_accuracy: 0.7369\n",
      "Epoch 48/50\n",
      "6186/6186 [==============================] - 269s 44ms/sample - loss: 0.5910 - accuracy: 0.7163 - val_loss: 0.5913 - val_accuracy: 0.7413\n",
      "Epoch 49/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.5933 - accuracy: 0.7100 - val_loss: 0.5894 - val_accuracy: 0.7384\n",
      "Epoch 50/50\n",
      "6186/6186 [==============================] - 275s 45ms/sample - loss: 0.5949 - accuracy: 0.7129 - val_loss: 0.5881 - val_accuracy: 0.7398\n"
     ]
    }
   ],
   "source": [
    "#train, then print validation scores\n",
    "history = model.fit(train_images, train_target, validation_split=validation_split, epochs=epoch_number, batch_size=batch_size, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#analysis: It seem I may need to decrease my LR after epoch 30? I do not seem to be over training, but maybe am running into\n",
    "#rocky area around epoch 30 where I am overshooting the convergence. Doesn't seem to be a smooth decrease after epoch 30?\n",
    "\n",
    "#I am altogether unsure of how to interpret. or how to change LR on the fly for that matter...\n",
    "\n",
    "#I am also worried about the fact that I do not have R and B data, because I know a big feature should be blue light vs red light\n",
    "\n",
    "#Note, this was also done without any data augmentation.\n",
    "\n",
    "#note, 0.905^30 = 0.05; 0.93^30 = 0.1; actually seems more likely that epoch=12 is where we start to come apart\n",
    "#so note, 0.83^12 = 0.1, 0.7^12 = 0.01\n",
    "#might consider that we should decay the learning rate so that we decrease is by a signicant amount by this epoch so that we\n",
    "#avoid the bumpy bit and keep moving smoothly??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2292/2292 [==============================] - 18s 8ms/sample - loss: 0.5957 - accuracy: 0.7295\n",
      "Test accuracy: 0.7294939\n",
      "Test loss: 0.5956907299384605\n"
     ]
    }
   ],
   "source": [
    "#model.summary()\n",
    "test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "#0.82 with LR = 3e-5, batch size=64, epochs=20, dropout=0.40.\n",
    "\n",
    "#0.82 with LR 3e-4, batch size=64, epochs=10, dropout=0.4.\n",
    "\n",
    "#LR 3e-3 caused no training, random guesses\n",
    "\n",
    "#LR 5e-4 slightly too high, didn't train as well as 3e-4 \n",
    "\n",
    "#last attempt on this notebook:\n",
    "#LR = 3e-4, 50 epochs, 64 batch size, dropout=0.4; test accuracy=0.8032\n",
    "\n",
    "#with all three channels, and a lr 2e-6, ran into small volatility problems, maxed out accuracy around 0.77, in 25 epochs.\n",
    "#will decrease lr to 1e-7 to get rid of volatility issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186 samples, validate on 688 samples\n",
      "Epoch 1/50\n",
      "6186/6186 [==============================] - 273s 44ms/sample - loss: 0.5888 - accuracy: 0.7144 - val_loss: 0.5868 - val_accuracy: 0.7442\n",
      "Epoch 2/50\n",
      "6186/6186 [==============================] - 275s 45ms/sample - loss: 0.5950 - accuracy: 0.7113 - val_loss: 0.5853 - val_accuracy: 0.7456\n",
      "Epoch 3/50\n",
      "6186/6186 [==============================] - 274s 44ms/sample - loss: 0.5935 - accuracy: 0.7095 - val_loss: 0.5836 - val_accuracy: 0.7442\n",
      "Epoch 4/50\n",
      "6186/6186 [==============================] - 269s 43ms/sample - loss: 0.5887 - accuracy: 0.7168 - val_loss: 0.5821 - val_accuracy: 0.7427\n",
      "Epoch 5/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.5806 - accuracy: 0.7224 - val_loss: 0.5807 - val_accuracy: 0.7442\n",
      "Epoch 6/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.5835 - accuracy: 0.7156 - val_loss: 0.5796 - val_accuracy: 0.7456\n",
      "Epoch 7/50\n",
      "6186/6186 [==============================] - 272s 44ms/sample - loss: 0.5871 - accuracy: 0.7132 - val_loss: 0.5780 - val_accuracy: 0.7427\n",
      "Epoch 8/50\n",
      "6186/6186 [==============================] - 269s 43ms/sample - loss: 0.5839 - accuracy: 0.7173 - val_loss: 0.5771 - val_accuracy: 0.7427\n",
      "Epoch 9/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.5880 - accuracy: 0.7152 - val_loss: 0.5755 - val_accuracy: 0.7471\n",
      "Epoch 10/50\n",
      "6186/6186 [==============================] - 269s 44ms/sample - loss: 0.5838 - accuracy: 0.7160 - val_loss: 0.5743 - val_accuracy: 0.7471\n",
      "Epoch 11/50\n",
      "6186/6186 [==============================] - 270s 44ms/sample - loss: 0.5830 - accuracy: 0.7134 - val_loss: 0.5734 - val_accuracy: 0.7471\n",
      "Epoch 12/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.5782 - accuracy: 0.7197 - val_loss: 0.5722 - val_accuracy: 0.7515\n",
      "Epoch 13/50\n",
      "6186/6186 [==============================] - 268s 43ms/sample - loss: 0.5829 - accuracy: 0.7131 - val_loss: 0.5714 - val_accuracy: 0.7515\n",
      "Epoch 14/50\n",
      "6186/6186 [==============================] - 269s 44ms/sample - loss: 0.5749 - accuracy: 0.7177 - val_loss: 0.5702 - val_accuracy: 0.7515\n",
      "Epoch 15/50\n",
      "6186/6186 [==============================] - 283s 46ms/sample - loss: 0.5792 - accuracy: 0.7218 - val_loss: 0.5690 - val_accuracy: 0.7515\n",
      "Epoch 16/50\n",
      "6186/6186 [==============================] - 311s 50ms/sample - loss: 0.5800 - accuracy: 0.7165 - val_loss: 0.5682 - val_accuracy: 0.7515\n",
      "Epoch 17/50\n",
      "6186/6186 [==============================] - 298s 48ms/sample - loss: 0.5783 - accuracy: 0.7142 - val_loss: 0.5670 - val_accuracy: 0.7529\n",
      "Epoch 18/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5758 - accuracy: 0.7169 - val_loss: 0.5659 - val_accuracy: 0.7558\n",
      "Epoch 19/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5756 - accuracy: 0.7129 - val_loss: 0.5649 - val_accuracy: 0.7558\n",
      "Epoch 20/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5767 - accuracy: 0.7199 - val_loss: 0.5644 - val_accuracy: 0.7558\n",
      "Epoch 21/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5734 - accuracy: 0.7190 - val_loss: 0.5630 - val_accuracy: 0.7558\n",
      "Epoch 22/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5742 - accuracy: 0.7194 - val_loss: 0.5617 - val_accuracy: 0.7573\n",
      "Epoch 23/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5728 - accuracy: 0.7179 - val_loss: 0.5612 - val_accuracy: 0.7573\n",
      "Epoch 24/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5766 - accuracy: 0.7181 - val_loss: 0.5603 - val_accuracy: 0.7573\n",
      "Epoch 25/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5742 - accuracy: 0.7197 - val_loss: 0.5595 - val_accuracy: 0.7573\n",
      "Epoch 26/50\n",
      "6186/6186 [==============================] - 281s 45ms/sample - loss: 0.5667 - accuracy: 0.7257 - val_loss: 0.5583 - val_accuracy: 0.7573\n",
      "Epoch 27/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5720 - accuracy: 0.7242 - val_loss: 0.5575 - val_accuracy: 0.7573\n",
      "Epoch 28/50\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5708 - accuracy: 0.7211 - val_loss: 0.5569 - val_accuracy: 0.7573\n",
      "Epoch 29/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5700 - accuracy: 0.7221 - val_loss: 0.5555 - val_accuracy: 0.7573\n",
      "Epoch 30/50\n",
      "6186/6186 [==============================] - 284s 46ms/sample - loss: 0.5700 - accuracy: 0.7169 - val_loss: 0.5548 - val_accuracy: 0.7587\n",
      "Epoch 31/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5739 - accuracy: 0.7184 - val_loss: 0.5543 - val_accuracy: 0.7587\n",
      "Epoch 32/50\n",
      "6186/6186 [==============================] - 284s 46ms/sample - loss: 0.5643 - accuracy: 0.7244 - val_loss: 0.5534 - val_accuracy: 0.7602\n",
      "Epoch 33/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5646 - accuracy: 0.7247 - val_loss: 0.5530 - val_accuracy: 0.7587\n",
      "Epoch 34/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5680 - accuracy: 0.7273 - val_loss: 0.5520 - val_accuracy: 0.7602\n",
      "Epoch 35/50\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5615 - accuracy: 0.7247 - val_loss: 0.5513 - val_accuracy: 0.7587\n",
      "Epoch 36/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5719 - accuracy: 0.7242 - val_loss: 0.5506 - val_accuracy: 0.7573\n",
      "Epoch 37/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5679 - accuracy: 0.7218 - val_loss: 0.5497 - val_accuracy: 0.7558\n",
      "Epoch 38/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5617 - accuracy: 0.7305 - val_loss: 0.5492 - val_accuracy: 0.7558\n",
      "Epoch 39/50\n",
      "6186/6186 [==============================] - 281s 45ms/sample - loss: 0.5672 - accuracy: 0.7257 - val_loss: 0.5485 - val_accuracy: 0.7558\n",
      "Epoch 40/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5629 - accuracy: 0.7307 - val_loss: 0.5479 - val_accuracy: 0.7558\n",
      "Epoch 41/50\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5604 - accuracy: 0.7302 - val_loss: 0.5471 - val_accuracy: 0.7558\n",
      "Epoch 42/50\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5560 - accuracy: 0.7271 - val_loss: 0.5463 - val_accuracy: 0.7529\n",
      "Epoch 43/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5652 - accuracy: 0.7239 - val_loss: 0.5459 - val_accuracy: 0.7529\n",
      "Epoch 44/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5651 - accuracy: 0.7274 - val_loss: 0.5455 - val_accuracy: 0.7558\n",
      "Epoch 45/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5627 - accuracy: 0.7189 - val_loss: 0.5448 - val_accuracy: 0.7544\n",
      "Epoch 46/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5636 - accuracy: 0.7241 - val_loss: 0.5445 - val_accuracy: 0.7573\n",
      "Epoch 47/50\n",
      "6186/6186 [==============================] - 281s 45ms/sample - loss: 0.5550 - accuracy: 0.7300 - val_loss: 0.5434 - val_accuracy: 0.7587\n",
      "Epoch 48/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5596 - accuracy: 0.7300 - val_loss: 0.5428 - val_accuracy: 0.7616\n",
      "Epoch 49/50\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5593 - accuracy: 0.7266 - val_loss: 0.5422 - val_accuracy: 0.7631\n",
      "Epoch 50/50\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5570 - accuracy: 0.7342 - val_loss: 0.5417 - val_accuracy: 0.7631\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_target, validation_split=validation_split, epochs=epoch_number, batch_size=batch_size, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186 samples, validate on 688 samples\n",
      "Epoch 1/100\n",
      "6186/6186 [==============================] - 281s 45ms/sample - loss: 0.5610 - accuracy: 0.7289 - val_loss: 0.5414 - val_accuracy: 0.7631\n",
      "Epoch 2/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5590 - accuracy: 0.7253 - val_loss: 0.5406 - val_accuracy: 0.7602\n",
      "Epoch 3/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5587 - accuracy: 0.7252 - val_loss: 0.5402 - val_accuracy: 0.7602\n",
      "Epoch 4/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5511 - accuracy: 0.7359 - val_loss: 0.5396 - val_accuracy: 0.7602\n",
      "Epoch 5/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5568 - accuracy: 0.7237 - val_loss: 0.5392 - val_accuracy: 0.7587\n",
      "Epoch 6/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5607 - accuracy: 0.7289 - val_loss: 0.5387 - val_accuracy: 0.7587\n",
      "Epoch 7/100\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5545 - accuracy: 0.7368 - val_loss: 0.5383 - val_accuracy: 0.7602\n",
      "Epoch 8/100\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5539 - accuracy: 0.7328 - val_loss: 0.5377 - val_accuracy: 0.7587\n",
      "Epoch 9/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5539 - accuracy: 0.7341 - val_loss: 0.5372 - val_accuracy: 0.7602\n",
      "Epoch 10/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5547 - accuracy: 0.7260 - val_loss: 0.5368 - val_accuracy: 0.7602\n",
      "Epoch 11/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5552 - accuracy: 0.7313 - val_loss: 0.5361 - val_accuracy: 0.7587\n",
      "Epoch 12/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5556 - accuracy: 0.7287 - val_loss: 0.5357 - val_accuracy: 0.7602\n",
      "Epoch 13/100\n",
      "6186/6186 [==============================] - 281s 45ms/sample - loss: 0.5549 - accuracy: 0.7292 - val_loss: 0.5353 - val_accuracy: 0.7587\n",
      "Epoch 14/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5547 - accuracy: 0.7304 - val_loss: 0.5349 - val_accuracy: 0.7587\n",
      "Epoch 15/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5547 - accuracy: 0.7320 - val_loss: 0.5345 - val_accuracy: 0.7587\n",
      "Epoch 16/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5526 - accuracy: 0.7326 - val_loss: 0.5340 - val_accuracy: 0.7587\n",
      "Epoch 17/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5515 - accuracy: 0.7318 - val_loss: 0.5337 - val_accuracy: 0.7587\n",
      "Epoch 18/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5536 - accuracy: 0.7291 - val_loss: 0.5333 - val_accuracy: 0.7587\n",
      "Epoch 19/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5529 - accuracy: 0.7308 - val_loss: 0.5329 - val_accuracy: 0.7573\n",
      "Epoch 20/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5465 - accuracy: 0.7339 - val_loss: 0.5325 - val_accuracy: 0.7573\n",
      "Epoch 21/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5498 - accuracy: 0.7367 - val_loss: 0.5319 - val_accuracy: 0.7573\n",
      "Epoch 22/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5478 - accuracy: 0.7336 - val_loss: 0.5314 - val_accuracy: 0.7587\n",
      "Epoch 23/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5495 - accuracy: 0.7363 - val_loss: 0.5310 - val_accuracy: 0.7587\n",
      "Epoch 24/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5510 - accuracy: 0.7271 - val_loss: 0.5306 - val_accuracy: 0.7587\n",
      "Epoch 25/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5539 - accuracy: 0.7321 - val_loss: 0.5305 - val_accuracy: 0.7587\n",
      "Epoch 26/100\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5474 - accuracy: 0.7383 - val_loss: 0.5301 - val_accuracy: 0.7587\n",
      "Epoch 27/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5488 - accuracy: 0.7320 - val_loss: 0.5297 - val_accuracy: 0.7587\n",
      "Epoch 28/100\n",
      "6186/6186 [==============================] - 282s 46ms/sample - loss: 0.5482 - accuracy: 0.7310 - val_loss: 0.5292 - val_accuracy: 0.7587\n",
      "Epoch 29/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5477 - accuracy: 0.7401 - val_loss: 0.5288 - val_accuracy: 0.7573\n",
      "Epoch 30/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5519 - accuracy: 0.7262 - val_loss: 0.5286 - val_accuracy: 0.7587\n",
      "Epoch 31/100\n",
      "6186/6186 [==============================] - 277s 45ms/sample - loss: 0.5455 - accuracy: 0.7407 - val_loss: 0.5282 - val_accuracy: 0.7587\n",
      "Epoch 32/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5460 - accuracy: 0.7350 - val_loss: 0.5279 - val_accuracy: 0.7573\n",
      "Epoch 33/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5442 - accuracy: 0.7412 - val_loss: 0.5276 - val_accuracy: 0.7573\n",
      "Epoch 34/100\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5436 - accuracy: 0.7409 - val_loss: 0.5273 - val_accuracy: 0.7573\n",
      "Epoch 35/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5475 - accuracy: 0.7302 - val_loss: 0.5271 - val_accuracy: 0.7558\n",
      "Epoch 36/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5454 - accuracy: 0.7333 - val_loss: 0.5266 - val_accuracy: 0.7558\n",
      "Epoch 37/100\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5463 - accuracy: 0.7417 - val_loss: 0.5263 - val_accuracy: 0.7587\n",
      "Epoch 38/100\n",
      "6186/6186 [==============================] - 308s 50ms/sample - loss: 0.5425 - accuracy: 0.7342 - val_loss: 0.5260 - val_accuracy: 0.7602\n",
      "Epoch 39/100\n",
      "6186/6186 [==============================] - 331s 53ms/sample - loss: 0.5475 - accuracy: 0.7373 - val_loss: 0.5257 - val_accuracy: 0.7587\n",
      "Epoch 40/100\n",
      "6186/6186 [==============================] - 314s 51ms/sample - loss: 0.5457 - accuracy: 0.7315 - val_loss: 0.5254 - val_accuracy: 0.7602\n",
      "Epoch 41/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5433 - accuracy: 0.7355 - val_loss: 0.5252 - val_accuracy: 0.7587\n",
      "Epoch 42/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5445 - accuracy: 0.7407 - val_loss: 0.5249 - val_accuracy: 0.7602\n",
      "Epoch 43/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5468 - accuracy: 0.7352 - val_loss: 0.5247 - val_accuracy: 0.7602\n",
      "Epoch 44/100\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5446 - accuracy: 0.7371 - val_loss: 0.5244 - val_accuracy: 0.7587\n",
      "Epoch 45/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5422 - accuracy: 0.7423 - val_loss: 0.5242 - val_accuracy: 0.7587\n",
      "Epoch 46/100\n",
      "6186/6186 [==============================] - 283s 46ms/sample - loss: 0.5423 - accuracy: 0.7354 - val_loss: 0.5239 - val_accuracy: 0.7602\n",
      "Epoch 47/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5443 - accuracy: 0.7392 - val_loss: 0.5235 - val_accuracy: 0.7602\n",
      "Epoch 48/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5366 - accuracy: 0.7409 - val_loss: 0.5232 - val_accuracy: 0.7645\n",
      "Epoch 49/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5364 - accuracy: 0.7428 - val_loss: 0.5229 - val_accuracy: 0.7616\n",
      "Epoch 50/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5440 - accuracy: 0.7405 - val_loss: 0.5227 - val_accuracy: 0.7602\n",
      "Epoch 51/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5404 - accuracy: 0.7388 - val_loss: 0.5224 - val_accuracy: 0.7631\n",
      "Epoch 52/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5457 - accuracy: 0.7368 - val_loss: 0.5222 - val_accuracy: 0.7631\n",
      "Epoch 53/100\n",
      "6186/6186 [==============================] - 284s 46ms/sample - loss: 0.5399 - accuracy: 0.7397 - val_loss: 0.5220 - val_accuracy: 0.7645\n",
      "Epoch 54/100\n",
      "6186/6186 [==============================] - 280s 45ms/sample - loss: 0.5449 - accuracy: 0.7388 - val_loss: 0.5218 - val_accuracy: 0.7645\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5425 - accuracy: 0.7405 - val_loss: 0.5216 - val_accuracy: 0.7645\n",
      "Epoch 56/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5366 - accuracy: 0.7378 - val_loss: 0.5213 - val_accuracy: 0.7645\n",
      "Epoch 57/100\n",
      "6186/6186 [==============================] - 278s 45ms/sample - loss: 0.5383 - accuracy: 0.7417 - val_loss: 0.5210 - val_accuracy: 0.7645\n",
      "Epoch 58/100\n",
      "6186/6186 [==============================] - 279s 45ms/sample - loss: 0.5431 - accuracy: 0.7355 - val_loss: 0.5208 - val_accuracy: 0.7645\n",
      "Epoch 59/100\n",
      "1344/6186 [=====>........................] - ETA: 3:40 - loss: 0.5379 - accuracy: 0.7493"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-a3f81466c0aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\DAMLA\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DAMLA\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DAMLA\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3217\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[0;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DAMLA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DAMLA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DAMLA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 415\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    416\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DAMLA\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_images, train_target, validation_split=validation_split, epochs=100, batch_size=batch_size, verbose=1, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
