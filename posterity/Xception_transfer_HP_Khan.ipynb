{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "import os\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import shift\n",
    "from keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "target_path = \"C:\\\\Users\\\\awe2\\\\DL_DES-master\\\\data\\\\sdss-galaxyzoo\\\\high_certainty\\\\sdss_metadata\\\\\"\n",
    "\n",
    "#path = 'image_arrays_new_new\\\\'\n",
    "#validation_path = path + 'validation'\n",
    "#training_path = path + 'training'\n",
    "#test_path = path + 'test'\n",
    "\n",
    "#model variables\n",
    "batch_size = 32 #\n",
    "learning_rate = 1e-4 \n",
    "\n",
    "params = {'dim': (120,120),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "#more parameters means more prone to overfitting, and I am 5/3 times worse on parameters compared to the paper I have\n",
    "#based this on. (5 bands instead of 3) I need to find ways to add more regularization, or otherwise might try reducing my number\n",
    "#of layers to reduce the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(120,120), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "     #   'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "    #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "    #'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "    # Initialization\n",
    "\n",
    "        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=int)\n",
    "        \n",
    "        X_resized = np.zeros((self.batch_size, 224, 224, self.n_channels), dtype=int)\n",
    "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "      \n",
    "      # Generate data and perform augmentation\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "          # Store sample\n",
    "            X[i,:,:,:] = np.load('HP_inputs/' + ID + '.npy')[:,:,1:4]\n",
    "            #X[i,4:68,4:68,:] = np.load('image_arrays/' + ID + '.npy')[:,:,1:4] \n",
    "            \n",
    "            #the arrays are saved as u,g,i,r,z . i want to provide it in order of i,r,g\n",
    "            i_filter = X[i,:,:,0]\n",
    "            r_filter = X[i,:,:,1]\n",
    "            g_filter = X[i,:,:,2]\n",
    "            \n",
    "            X[i,:,:,0] = i_filter\n",
    "            X[i,:,:,1] = r_filter\n",
    "            X[i,:,:,2] = g_filter\n",
    "            #resize\n",
    "            X_resized[i,:,:,:] = (255 * resize(X[i,:,:,:], (224,224,3))).astype(np.uint8)\n",
    "            \n",
    "            #flip\n",
    "            if random.random() > 0.5:\n",
    "                X_resized[i,] = np.flip(X_resized[i,],0)\n",
    "            if random.random() > 0.5:\n",
    "                X_resized[i,] = np.flip(X_resized[i,],1)\n",
    "            \n",
    "            #shift\n",
    "            if random.random() > 0.5 :\n",
    "                X_resized[i,] = shift(X_resized[i,], (4,0,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X_resized[i,] = shift(X_resized[i,], (-4,0,0), mode='nearest')\n",
    "                              \n",
    "            if random.random() > 0.5 :\n",
    "                X_resized[i,] = shift(X_resized[i,], (0,4,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X_resized[i,] = shift(X_resized[i,], (0,-4,0), mode='nearest')\n",
    "          \n",
    "            #zoom in/out\n",
    "            zoom_factor = random.uniform(0.75,1.3)\n",
    "            X_resized[i,] = clipped_zoom(X_resized[i,],zoom_factor)\n",
    "            \n",
    "            #rotate\n",
    "            angle = 45*random.random()\n",
    "            X_resized[i,] = skimage.transform.rotate(X_resized[i,], angle=angle, mode='reflect')\n",
    "            \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "    \n",
    "        if self.n_classes > 2:\n",
    "            return X_resized, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X_resized, y\n",
    "\n",
    "    def __len__(self):\n",
    "    #'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    #  'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "      # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the targets.\n",
    "a = []\n",
    "for file in (os.listdir(target_path)):\n",
    "    target = pd.read_csv(target_path+file,usecols=[14])\n",
    "    a.append((target[\"target\"].values))\n",
    "targets = np.concatenate([a[0],a[1],a[2],a[3],a[4],a[5],a[6],a[7],a[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.txt\",\"r\") as inf:\n",
    "    labels = eval(inf.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we shuffle our data list, and partition into train, test, and validation sets.\n",
    "data_list = os.listdir(\"HP_inputs\")\n",
    "random.shuffle(data_list)\n",
    "#we want 20% of the data reserved for testing, and then another 15% reserved for validation.\n",
    "top_index = len(data_list)\n",
    "first_index = int(round(top_index * 0.65))\n",
    "second_index = int(round(top_index * 0.15)) + first_index\n",
    "\n",
    "train_list = data_list[0:first_index]\n",
    "val_list = data_list[first_index:second_index]\n",
    "test_list = data_list[second_index::]\n",
    "\n",
    "for i,file in enumerate(train_list):\n",
    "    train_list[i] = file.split('.')[0]\n",
    "for i,file in enumerate(val_list):\n",
    "    val_list[i] = file.split('.')[0]\n",
    "\n",
    "partition = {'train':train_list,'validation':val_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so this is pretty neat, you can create a keras callback to display on tensorboard using a simplified summary tf api\n",
    "\n",
    "#and also this is an example of how to change the lr on the fly, which is pretty handy\n",
    "#https://keras.io/callbacks/\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "    file_writer.set_as_default()\n",
    "\"\"\"\n",
    "def lr_schedule(epoch,lr):\n",
    "\n",
    "#Returns a custom learning rate that decreases as epochs progress.\n",
    "    if epoch > 5:\n",
    "        lr = 1e-5\n",
    "    if epoch > 10:\n",
    "        lr = 1e-6\n",
    "\n",
    "    tf.summary.scalar('learning_rate', tensor=lr)\n",
    "    return lr\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "#logdir=\"summaries/scalars/\" + str(datetime.datetime.now().timestamp())\n",
    "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "#                                                   histogram_freq=1,\n",
    "#                                                   write_graph=False,\n",
    "#                                                   write_grads=True,)\n",
    "#                                                    write_images=True)\n",
    "#will it still print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbase_model = Xception(input_shape=(72,72,3), weights=\\'imagenet\\', include_top=False)\\nx = base_model.output\\nx = keras.layers.GlobalAveragePooling2D()(x)\\nx = keras.layers.Dense(1024, activation=\\'relu\\')(x)\\nx = keras.layers.Dropout(0.7)(x)\\nx = keras.layers.Dense(1024, activation=\"relu\", name=\\'second_last_layer\\')(x)\\npredictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\\n\\nmodel_final = Model(inputs=base_model.input, outputs=predictions)\\n\\nfor layer in base_model.layers:\\n    layer.trainable = False\\n\\nmodel_final.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "base_model = Xception(input_shape=(72,72,3), weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.7)(x)\n",
    "x = keras.layers.Dense(1024, activation=\"relu\", name='second_last_layer')(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_final = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_final.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n",
      "181\n"
     ]
    }
   ],
   "source": [
    "steps_to_take = int(len(train_list)/batch_size)\n",
    "val_steps_to_take = int(len(val_list)/batch_size)\n",
    "                #typically be equal to the number of unique samples if your dataset\n",
    "                #divided by the batch size.\n",
    "\n",
    "print(steps_to_take)\n",
    "print(val_steps_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 08:58:10.368887  5632 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "#lets try it how we ran VGG16...\n",
    "\"\"\"\n",
    "Input_layer = layers.Input(shape=(32,32,3))\n",
    "base_model = vgg16.VGG16(include_top=False, weights='imagenet',input_tensor=Input_layer)\n",
    "\n",
    "x=base_model.output\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dropout(dropout)(x)\n",
    "x=layers.Dense(1024,activation='relu')(x)\n",
    "\"\"\"\n",
    "Input_layer = keras.layers.Input(shape=(224,224,3))\n",
    "base_model = keras.applications.Xception(input_tensor=Input_layer,weights='imagenet',include_top=False)\n",
    "\n",
    "x= base_model.output\n",
    "x= keras.layers.GlobalAveragePooling2D()(x)\n",
    "x= keras.layers.Dense(1024, activation=tf.nn.relu)(x)\n",
    "x= keras.layers.Dropout(0.7)(x)\n",
    "x= keras.layers.Dense(128, activation=tf.nn.relu)(x)\n",
    "preds= keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,layer in enumerate(model.layers):\n",
    "#    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to train some of the later layers it seems; not just my dense. \n",
    "#Huerta and kahn use 41, they have access to bluewaters tho...\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkeras.backend.clear_session()\\ntf.reset_default_graph()\\n\\nbase_model = keras.applications.Xception(input_shape=(72,72,3),weights=\\'imagenet\\',include_top=False)\\n#base_model = keras.applications.Xception(weights=\\'imagenet\\',include_top=False)\\nfor layer in base_model.layers:\\n    layer.trainable = False\\n\\nmodel = keras.Sequential([])\\nmodel.add(keras.layers.InputLayer((72,72,3), name=\\'input\\'))\\nmodel.add(base_model)\\nmodel.add(keras.layers.GlobalAveragePooling2D(name=\\'global_after_transfer\\'))\\nmodel.add(keras.layers.Dense(1024, activation=tf.nn.relu,name=\\'first_dense\\'))\\nmodel.add(keras.layers.Dropout(0.7))\\nmodel.add(keras.layers.Dense(1024, activation=tf.nn.relu,name=\\'second_dense\\'))\\nmodel.add(keras.layers.Dense(1, activation=tf.nn.sigmoid,name=\\'predictor\\'))\\n\\nmodel.compile(loss=keras.losses.binary_crossentropy, optimizer = keras.optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nope this doesnt work\n",
    "\"\"\"\n",
    "keras.backend.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "base_model = keras.applications.Xception(input_shape=(72,72,3),weights='imagenet',include_top=False)\n",
    "#base_model = keras.applications.Xception(weights='imagenet',include_top=False)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = keras.Sequential([])\n",
    "model.add(keras.layers.InputLayer((72,72,3), name='input'))\n",
    "model.add(base_model)\n",
    "model.add(keras.layers.GlobalAveragePooling2D(name='global_after_transfer'))\n",
    "model.add(keras.layers.Dense(1024, activation=tf.nn.relu,name='first_dense'))\n",
    "model.add(keras.layers.Dropout(0.7))\n",
    "model.add(keras.layers.Dense(1024, activation=tf.nn.relu,name='second_dense'))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid,name='predictor'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer = keras.optimizers.Adam(lr=learning_rate), metrics=[\"accuracy\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an optimizer, loss, and accuracy metric.\n",
    "adam = tf.keras.optimizers.Adam(1e-5)\n",
    "model.compile(optimizer=adam, loss=keras.losses.binary_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"models//Xception-khan-0.h5\"\n",
    "ModelCheckpointCB = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:605: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784/785 [============================>.] - ETA: 7s - loss: 0.6966 - acc: 0.4968 \n",
      "Epoch 00001: val_loss improved from inf to 0.69315, saving model to models//Xception-khan-0.h5\n",
      "785/785 [==============================] - 7607s 10s/step - loss: 0.6966 - acc: 0.4966 - val_loss: 0.6931 - val_acc: 0.4974\n",
      "Epoch 2/5\n",
      "784/785 [============================>.] - ETA: 7s - loss: 0.6949 - acc: 0.5003 \n",
      "Epoch 00002: val_loss did not improve from 0.69315\n",
      "785/785 [==============================] - 7004s 9s/step - loss: 0.6948 - acc: 0.5004 - val_loss: 0.6932 - val_acc: 0.4979\n",
      "Epoch 3/5\n",
      "784/785 [============================>.] - ETA: 7s - loss: 0.6945 - acc: 0.5014 \n",
      "Epoch 00003: val_loss did not improve from 0.69315\n",
      "785/785 [==============================] - 6987s 9s/step - loss: 0.6945 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4979\n",
      "Epoch 4/5\n",
      " 40/785 [>.............................] - ETA: 1:05:04 - loss: 0.6944 - acc: 0.4930"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-33d18e3dc901>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_steps_to_take\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                     callbacks=[ModelCheckpointCB,lr_callback])\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m       \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[1;34m(generator, mode)\u001b[0m\n\u001b[0;32m    360\u001b[0m   \u001b[1;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=5,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps_to_take,\n",
    "                    verbose=1,\n",
    "                    callbacks=[ModelCheckpointCB,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:41]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[41:]:\n",
    "    layer.trainable=True\n",
    "    \n",
    "filepath = \"models//Xception-khan-1.h5\"\n",
    "ModelCheckpointCB = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(1e-6)\n",
    "model.compile(optimizer=adam, loss=keras.losses.binary_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "hist2 = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=5,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps_to_take,\n",
    "                    verbose=1,\n",
    "                    callbacks=[ModelCheckpointCB,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "#print('Test accuracy:', test_acc)\n",
    "#print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_prob = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source list\n",
    "\"\"\"\n",
    "https://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/\n",
    "\n",
    "https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "\n",
    "https://arxiv.org/pdf/1711.05744.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1807.00807.pdf\n",
    "\n",
    "https://github.com/jameslawlor/kaggle_galaxy_zoo/blob/master/galaxy_zoo_keras.ipynb\n",
    "\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "\n",
    "https://distill.pub/2018/building-blocks/ what I want to do with this after it is working.\n",
    "\n",
    "https://github.com/khanx169/DL_DES/blob/master/deeplearning/Xception_final.ipynb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "training just the top layers; 1 epoch like Khan\n",
    "\n",
    "784/785 [============================>.] - ETA: 2s - loss: 0.3144 - acc: 0.8830\n",
    "Epoch 00001: val_loss improved from inf to 15.60131, saving model to models//Xception-khan-0.h5\n",
    "785/785 [==============================] - 2440s 3s/step - loss: 0.3143 - acc: 0.8831 - val_loss: 15.6013 - val_acc: 0.5312\n",
    "\n",
    "And then training all layers after 41:\n",
    "\n",
    "Epoch 1/5\n",
    "784/785 [============================>.] - ETA: 1s - loss: 0.0695 - acc: 0.9696\n",
    "Epoch 00001: val_loss improved from inf to 59.03588, saving model to models//Xception-khan-1.h5\n",
    "785/785 [==============================] - 1865s 2s/step - loss: 0.0696 - acc: 0.9695 - val_loss: 59.0359 - val_acc: 0.4722\n",
    "Epoch 2/5\n",
    "784/785 [============================>.] - ETA: 1s - loss: 0.0417 - acc: 0.9805\n",
    "Epoch 00002: val_loss did not improve from 59.03588\n",
    "785/785 [==============================] - 1841s 2s/step - loss: 0.0417 - acc: 0.9806 - val_loss: 140.0926 - val_acc: 0.5432\n",
    "Epoch 3/5\n",
    "784/785 [============================>.] - ETA: 1s - loss: 0.0381 - acc: 0.9814\n",
    "Epoch 00003: val_loss did not improve from 59.03588\n",
    "785/785 [==============================] - 1839s 2s/step - loss: 0.0381 - acc: 0.9814 - val_loss: 160.0299 - val_acc: 0.5516\n",
    "Epoch 4/5\n",
    "784/785 [============================>.] - ETA: 1s - loss: 0.0353 - acc: 0.9823\n",
    "Epoch 00004: val_loss did not improve from 59.03588\n",
    "785/785 [==============================] - 1835s 2s/step - loss: 0.0354 - acc: 0.9822 - val_loss: 215.8511 - val_acc: 0.5551\n",
    "Epoch 5/5\n",
    "784/785 [============================>.] - ETA: 1s - loss: 0.0348 - acc: 0.9823\n",
    "Epoch 00005: val_loss did not improve from 59.03588\n",
    "785/785 [==============================] - 1840s 2s/step - loss: 0.0349 - acc: 0.9823 - val_loss: 193.4825 - val_acc: 0.5447\n",
    "\n",
    "#training all layers after the input:\n",
    "\n",
    "RESOURCE ERROR\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
