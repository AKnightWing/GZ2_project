{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "processed_data = np.load('Full_array.npy')\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#The size of the dataset is 10,000; but I only filled the first 9166 with values, the rest are zeros. (shouldn't be counted)\n",
    "number = 9166\n",
    "processed_data = processed_data[0:number]\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to push accuracy to over 90%\n",
    "\n",
    "#idea number 1: run a set of high percentage accuracy classifications through the NN (nope)\n",
    "\n",
    "#idea number 2: clean the training set by running through and deleting the bad examples from my data aquisition, were going to \n",
    "#set all arrays of zero to be class A. If I feed this NN nothing, I want it to tell me it is odd. (yup)\n",
    "\n",
    "#first lets see what doing number 2 will get us.\n",
    "\n",
    "#augment data set manually (worked)\n",
    "\n",
    "#change LR (Adam is adaptive: so no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to normalize our iamge data to go from 0 to 1\n",
    "processed_data = processed_data.reshape(np.size(processed_data))\n",
    "processed_data = (processed_data - min(processed_data))/ (max(processed_data) - min(processed_data))\n",
    "processed_data = processed_data.reshape(number,28,28)\n",
    "#I actually am not sure how it is scaled. however, some of the pixels are negative for some reason???\n",
    "\n",
    "#also, this did not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters:\n",
    "HP_allowed_confidence = 0.98\n",
    "test_train_split = 0.85\n",
    "batch_size = 256\n",
    "epoch_number = 15\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.3\n",
    "CNL1_filters = 32\n",
    "CNL1_kernal_size = 3\n",
    "MPL1_pool_size= (2,2)\n",
    "MPL1_strides = 2\n",
    "CNL2_filters = 64\n",
    "CNL2_kernal_size = 3\n",
    "MPL2_pool_size = (2,2)\n",
    "MPL2_strides = 2\n",
    "\n",
    "#I have a non-round number of examples\n",
    "train_split_indice = int(np.round(test_train_split*number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in my dataset of targets, targets are strings labels under the name \"Class\"\n",
    "galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv/zoo2MainSpecz.csv\", usecols=[2,3,4,8,15,21,27], nrows=number)\n",
    "#galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv/zoo2MainSpecz.csv\", nrows=number)\n",
    "Class = galaxyzoo[\"gz2class\"].values\n",
    "RA = galaxyzoo['ra'].values\n",
    "DEC = galaxyzoo['dec'].values\n",
    "Spiral = galaxyzoo['t01_smooth_or_features_a02_features_or_disk_debiased'].values\n",
    "Elliptical = galaxyzoo['t01_smooth_or_features_a01_smooth_debiased'].values\n",
    "Anythingelse = galaxyzoo['t01_smooth_or_features_a03_star_or_artifact_debiased'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to take the first character of the Class string and interpret as a integer, ala MNIST example code\n",
    "dictionary = {'A':int(2),'E':int(1),'S':int(0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resave using my dictionary\n",
    "target = np.empty((len(Class)))\n",
    "for i in range(len(Class)):\n",
    "    target[i] = int(dictionary[Class[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through, find the arrays of zero, set that target to 'A' = 2\n",
    "for i in range(len(target)):\n",
    "    if processed_data[i].any() == 0:\n",
    "        target[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split my data between training and test sets\n",
    "train_target = target[0:train_split_indice]\n",
    "test_target = target[train_split_indice:number]\n",
    "train_images = processed_data[0:train_split_indice]\n",
    "test_images = processed_data[train_split_indice:number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31164,)\n",
      "(31164, 28, 28)\n",
      "31164\n",
      "(1375,)\n"
     ]
    }
   ],
   "source": [
    "#Create 3 more images from each of my training and testing images that is each image but flipped 90 degrees...\n",
    "train_images_flip1 = np.flip(train_images,1)\n",
    "train_images_flip2 = np.flip(train_images,2)\n",
    "train_images_flip3 = np.flip(train_images_flip1,2)\n",
    "\n",
    "flipped_img = np.append(train_images, train_images_flip1, 0)\n",
    "flipped_img = np.append(flipped_img, train_images_flip2, 0)\n",
    "flipped_img = np.append(flipped_img, train_images_flip3, 0)\n",
    "\n",
    "flipped_tar = np.append(train_target,train_target, 0)\n",
    "flipped_tar = np.append(flipped_tar,train_target, 0)\n",
    "flipped_tar = np.append(flipped_tar,train_target, 0)\n",
    "\n",
    "#test_images_flip1 = np.flip(test_images,1)\n",
    "#test_images_flip2 = np.flip(test_images,2)\n",
    "#test_images_flip3 = np.flip(test_images_flip1,2)\n",
    "\n",
    "#test_images = np.append(test_images, test_images_flip1,0)\n",
    "#test_images = np.append(test_images, test_images_flip2,0)\n",
    "#test_images = np.append(test_images, test_images_flip3,0)\n",
    "\n",
    "#test_target = np.append(test_target,test_target,0)\n",
    "#test_target = np.append(test_target,test_target,0)\n",
    "\n",
    "print(np.shape(flipped_tar))\n",
    "print(np.shape(flipped_img))\n",
    "print(np.size(train_target)*4)\n",
    "\n",
    "print(np.shape(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = flipped_img\n",
    "train_target = flipped_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#rotate each image in the target_images by a random amount\n",
    "rotations_array = np.empty((31164,28,28))\n",
    "for i in range(np.shape(train_images)[0]):\n",
    "    degree = np.random.uniform(-45,45,1)\n",
    "    img = Image.fromarray(train_images[i])\n",
    "    rot = img.rotate(degree)\n",
    "    rot = np.asarray(rot)\n",
    "    rotations_array[i] = rot\n",
    "#now append rotations_array to train_images\n",
    "train_images = np.append(train_images, rotations_array,0)\n",
    "#now append the class labels to the train_target array\n",
    "train_target = np.append(train_target,train_target)\n",
    "\n",
    "\n",
    "#every time we run this segment, we increase our training set by a factor of 2. this means it will train in 120 * number of times\n",
    "# times 20 epochs = a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_clipped_zoom(img, zoom_factor):\n",
    "    \"\"\"\n",
    "    Center zoom in/out of the given image and returning an enlarged/shrinked view of \n",
    "    the image without changing dimensions\n",
    "    Args:\n",
    "        img : Image array\n",
    "        zoom_factor : amount of zoom as a ratio (0 to Inf)\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2] # It's also the final desired shape\n",
    "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
    "\n",
    "    ### Crop only the part that will remain in the result (more efficient)\n",
    "    # Centered bbox of the final desired size in resized (larger/smaller) image coordinates\n",
    "    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n",
    "    y2, x2 = y1 + height, x1 + width\n",
    "    bbox = np.array([y1,x1,y2,x2])\n",
    "    # Map back to original image coordinates\n",
    "    bbox = (bbox / zoom_factor).astype(np.int)\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Handle padding when downscaling\n",
    "    resize_height, resize_width = min(new_height, height), min(new_width, width)\n",
    "    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n",
    "    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n",
    "    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n",
    "\n",
    "    result = resize(cropped_img, (resize_width, resize_height))\n",
    "    result = np.pad(result, pad_spec, mode='constant')\n",
    "    assert result.shape[0] == height and result.shape[1] == width\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase by a factor of two again, like above\n",
    "rotations_array = np.empty((31164*2,28,28))\n",
    "for i in range(np.shape(train_images)[0]):\n",
    "    degree = np.random.uniform(-45,45,1)\n",
    "    img = Image.fromarray(train_images[i])\n",
    "    rot = img.rotate(degree)\n",
    "    zoom_factor = np.random.uniform(0.7,1.3,1)\n",
    "    rot = cv2_clipped_zoom(np.asarray(rot),zoom_factor)\n",
    "    #rot = rot.resize()\n",
    "    #rot = np.asarray(rot)\n",
    "    rotations_array[i] = rot\n",
    "#now append rotations_array to train_images\n",
    "train_images = np.append(train_images, rotations_array,0)\n",
    "#now append the class labels to the train_target array\n",
    "train_target = np.append(train_target,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to form a subset of our training examples that are probabilities that they are sorted correctly greater than %90\n",
    "#we will then train this dataset additional times.\n",
    "\"\"\"\n",
    "confidence = list()\n",
    "HP_indice = list()\n",
    "for i in range(len(train_images)):\n",
    "    if train_target[i] == 0:\n",
    "        confidence.append(Spiral[i])\n",
    "    if train_target[i] == 1:\n",
    "        confidence.append(Elliptical[i])\n",
    "    if train_target[i] == 2:\n",
    "        confidence.append(Anythingelse[i])\n",
    "    if confidence[i] >= HP_allowed_confidence:\n",
    "        HP_indice.append(i)\n",
    "train_weights = np.asarray(confidence)\n",
    "HP_target = np.empty(len(HP_indice))\n",
    "HP_images = np.empty((len(HP_indice),28,28))\n",
    "for i in range(len(HP_indice)):\n",
    "    HP_target[i] = train_target[HP_indice[i]]\n",
    "    HP_images[i] = train_images[HP_indice[i]]\n",
    "\n",
    "#print(len(HP_indice))\n",
    "HP_images = HP_images.reshape(len(HP_indice),28,28,1)\n",
    "train_images = train_images.reshape(train_split_indice,28,28,1)\n",
    "test_images = test_images.reshape(train_split_indice-number,28,28,1)\n",
    "print(np.shape(train_images))\n",
    "print(np.shape(HP_images))\n",
    "\"\"\"\n",
    "\n",
    "#I need this bottom part to come out, but delete it if we wanted the HP set again...\n",
    "train_images = train_images.reshape(train_split_indice*4*2*2,28,28,1)\n",
    "test_images = test_images.reshape((train_split_indice-number)*4*2*2,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\\n\\ndatagen = ImageDataGenerator(\\n        rotation_range=45,\\n        #width_shift_range=0.2,\\n        #height_shift_range=0.2,\\n        #zoom_range=0.2,\\n        horizontal_flip=True,\\n        vertical_flip=True,\\n        fill_mode='nearest')\\n\""
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next Idea: I want to augment my images to artificially create more data: technically, I should be allowed to do any\n",
    "#amount of flips and rotations because of the cosmological principle\n",
    "\n",
    "#if that doesn't work, I will just have to get more data. or add more layers...\n",
    "\n",
    "#Note: using this generator decreased performance, I dont know how it works. I do know how my manuel offline flips and rotations\n",
    "#work. And, those offline incresed performance.\n",
    "\n",
    "\"\"\"\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=45,\n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "#X=[1,2,3]\n",
    "#y = ['one', 'two', 'three']\n",
    "#X, y = shuffle(X, y, random_state=0)\n",
    "#print(X)\n",
    "#print(y)\n",
    "#train_images, train_target = shuffle(train_images, train_target, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define my model, using a CNN with 2 Convolutional layers, 2 max pool layers, 1 dense layer, 1 drop out layer, and another dense layer \n",
    "def create_model(dropout_rate=dropout_rate, learning_rate=learning_rate):\n",
    "    \n",
    "    model = keras.Sequential([])\n",
    "    model.add(keras.layers.Conv2D(input_shape=(28,28,1),filters=CNL1_filters,kernel_size=CNL1_kernal_size,padding=\"same\",activation=tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=MPL1_pool_size, strides=MPL1_strides))\n",
    "    model.add(keras.layers.Conv2D(filters=CNL2_filters,kernel_size=CNL2_kernal_size,padding=\"same\",activation=tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=MPL2_pool_size,strides=MPL2_strides))\n",
    "    #model.add(keras.layers.Dropout(rate=0.25))\n",
    "    #model.add(keras.layers.Conv2D(filters=128,kernel_size=CNL2_kernal_size,padding=\"same\",activation=tf.nn.relu))\n",
    "    #model.add(keras.layers.MaxPool2D(pool_size=MPL2_pool_size,strides=MPL2_strides))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=1024,activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=dropout_rate))\n",
    "    model.add(keras.layers.Dense(units=3,activation=tf.nn.softmax))\n",
    "    adam = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "    model.compile(optimizer=adam, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model with the high probability first, 2-3 epochs increased accuracy just slightly.\n",
    "#model=create_model(dropout_rate=dropout_rate, learning_rate=learning_rate)\n",
    "#model.fit(HP_images, HP_target, epochs=2, batch_size=batch_size, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()\n",
    "#test_loss, test_acc = model.evaluate(test_images.reshape(number - train_split_indice,28,28,1), test_target)\n",
    "#print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "124656/124656 [==============================] - 245s 2ms/step - loss: 0.3675 - acc: 0.8387\n",
      "Epoch 2/15\n",
      "124656/124656 [==============================] - 245s 2ms/step - loss: 0.3634 - acc: 0.8396\n",
      "Epoch 3/15\n",
      "124656/124656 [==============================] - 243s 2ms/step - loss: 0.3576 - acc: 0.8427\n",
      "Epoch 4/15\n",
      "124656/124656 [==============================] - 245s 2ms/step - loss: 0.3528 - acc: 0.8458\n",
      "Epoch 5/15\n",
      "124656/124656 [==============================] - 243s 2ms/step - loss: 0.3484 - acc: 0.8475\n",
      "Epoch 6/15\n",
      "124656/124656 [==============================] - 242s 2ms/step - loss: 0.3422 - acc: 0.8498\n",
      "Epoch 7/15\n",
      "124656/124656 [==============================] - 244s 2ms/step - loss: 0.3384 - acc: 0.8504\n",
      "Epoch 8/15\n",
      "124656/124656 [==============================] - 246s 2ms/step - loss: 0.3316 - acc: 0.8547\n",
      "Epoch 9/15\n",
      "124656/124656 [==============================] - 243s 2ms/step - loss: 0.3276 - acc: 0.8566\n",
      "Epoch 10/15\n",
      "124656/124656 [==============================] - 249s 2ms/step - loss: 0.3243 - acc: 0.8571\n",
      "Epoch 11/15\n",
      "124656/124656 [==============================] - 782s 6ms/step - loss: 0.3181 - acc: 0.8608\n",
      "Epoch 12/15\n",
      "124656/124656 [==============================] - 272s 2ms/step - loss: 0.3125 - acc: 0.8625\n",
      "Epoch 13/15\n",
      "124656/124656 [==============================] - 271s 2ms/step - loss: 0.3106 - acc: 0.8636\n",
      "Epoch 14/15\n",
      "124656/124656 [==============================] - 267s 2ms/step - loss: 0.3040 - acc: 0.8672\n",
      "Epoch 15/15\n",
      "124656/124656 [==============================] - 272s 2ms/step - loss: 0.3001 - acc: 0.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2865b68fa58>"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try training one epoch at a time and seeing what epoch when we maximize our accuracy; I fear overtraining\n",
    "\n",
    "#OTHER than that, my next idea is to change the architecture.... eventually I will need to build a RESnet anyways\n",
    "#model = create_model(dropout_rate=dropout_rate, learning_rate = learning_rate)\n",
    "#I want to only present a few images now for each epoch, this may help with overfitting\n",
    "model.fit(train_images, train_target, epochs=epoch_number, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "#for i in range(epoch_number):\n",
    "#    model.fit(train_images[0:train_split_indice], train_target[0:train_split_indice], epochs=1, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "#    test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "#    print('Test accuracy:', test_acc)\n",
    "#overtrained at epoch 18?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model(dropout_rate=dropout_rate, learning_rate = learning_rate)\n",
    "#model.fit(train_images, train_target, epochs=1, batch_size=batch_size, verbose=1, shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375/1375 [==============================] - 2s 1ms/step\n",
      "Test accuracy: 0.8407272728139704\n"
     ]
    }
   ],
   "source": [
    "#model.summary()\n",
    "test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "#0.848 with the zeros fixed\n",
    "#0.850 with the HP dataset implemented\n",
    "\n",
    "#0.822 with augmentation, rescaling\n",
    "#rescaling seems to worsen my performance; however: why are some of my pixel values negative?\n",
    "\n",
    "#0.842 with 50 epochs: doesn't seem to be over fitting, perhaps the data augmentation just takes more time to train???\n",
    "\n",
    "#0.852 with 75 epochs, maybe we need to decrease learning rate past 50???, using generator\n",
    "\n",
    "#0.857 w/ 75 epochs, using generator\n",
    "\n",
    "#0.864 with 20 epochs, using offline flips before the data set. dropout = 0.3, no HP set. perhaps we can train for 15 epochs with\n",
    "#LR  0.001 as usual, then train 5 epochs with LR decreased by factor of 10? \n",
    "\n",
    "#I dont think changing my LR will help, it appears Adam already adapts LR on the fly for the situation.\n",
    "#0.857 w/ droput rate increased to 0.3, will decrease it again... \n",
    "\n",
    "#0.864 with 15 epochs, dropout_rate = 0.25, with 124656 images after making two copies of flips and stuff.\n",
    "\n",
    "#0.852 with 20 epcohs, dropout rate = 0.5, LR = 0.004, batch_size = 128. The accuracy did not seem over trained by the end of the \n",
    "#20 epochs, therefore I will run it through another 20 to see what happens\n",
    "\n",
    "#result over trained...\n",
    "\n",
    "#CANT PUSH THE GODDAMN NETWORK OVER 0.864!!!! AHHH! I have implemented a zoom, stochastic methods of presenting images\n",
    "\n",
    "#Maybe just rescale the damn images???\n",
    "\n",
    "#0.840 after 15 epochs, flips, zooms, and rotations, and rescaled images from 0 to 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
