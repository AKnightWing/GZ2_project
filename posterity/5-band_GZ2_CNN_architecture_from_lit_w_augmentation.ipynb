{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "import os\n",
    "import skimage\n",
    "import random\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.ndimage import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "path = 'image_arrays_new_new\\\\'\n",
    "validation_path = path + 'validation'\n",
    "training_path = path + 'training'\n",
    "test_path = path + 'test'\n",
    "#model variables\n",
    "batch_size = 30 #\n",
    "epoch_number = 50\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "params = {'dim': (64,64),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 5,\n",
    "          'shuffle': True}\n",
    "\n",
    "\n",
    "#more parameters means more prone to overfitting, and I am 5/3 times worse on parameters compared to the paper I have\n",
    "#based this on. (5 bands instead of 3) I need to find ways to add more regularization, or otherwise might try reducing my number\n",
    "#of layers to reduce the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(64,64), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "     #   'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "    #'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "    #'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "    # Initialization\n",
    "    \n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "    \n",
    "      \n",
    "      # Generate data and perform augmentation\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            \n",
    "          # Store sample\n",
    "            X[i,] = np.load('image_arrays/' + ID + '.npy')\n",
    "                          \n",
    "            #flip\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],0)\n",
    "            if random.random() > 0.5:\n",
    "                X[i,] = np.flip(X[i,],1)\n",
    "            \n",
    "            #shift\n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (4,0,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (-4,0,0), mode='nearest')\n",
    "                              \n",
    "            if random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,4,0), mode='nearest')\n",
    "            elif random.random() > 0.5 :\n",
    "                X[i,] = shift(X[i,], (0,-4,0), mode='nearest')\n",
    "          \n",
    "            #zoom in/out\n",
    "            zoom_factor = random.uniform(0.75,1.3)\n",
    "            X[i,] = clipped_zoom(X[i,],zoom_factor)\n",
    "            \n",
    "            #rotate\n",
    "            angle = 45*random.random()\n",
    "            X[i,] = skimage.transform.rotate(X[i,], angle=angle, mode='reflect')\n",
    "            \n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "    \n",
    "        if self.n_classes > 2:\n",
    "            return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        else:\n",
    "            return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "    #'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    #  'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "      # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4099\n",
      "5887\n"
     ]
    }
   ],
   "source": [
    "galaxyzoo = pd.read_csv(\"zoo2MainSpecz.csv\", usecols=[8], nrows=10000)\n",
    "Class = galaxyzoo[\"gz2class\"].values\n",
    "dictionary = {'A':int(2),'E':np.array([0]),'S':np.array([1])}\n",
    "#resave using my dictionary\n",
    "target = np.empty((len(Class)))\n",
    "for i in range(len(Class)):\n",
    "    target[i] = dictionary[Class[i][0]]\n",
    "#target = target.astype(int)\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for i in target:\n",
    "    if i == np.array([0]):\n",
    "        count_0 += 1\n",
    "    if i == np.array([1]):\n",
    "        count_1 += 1\n",
    "\n",
    "print(count_0)\n",
    "print(count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = os.listdir(training_path)\n",
    "for i,file in enumerate(train_list):\n",
    "    train_list[i] = file.split('.')[0]\n",
    "val_list = os.listdir(validation_path)\n",
    "for i,file in enumerate(val_list):\n",
    "    val_list[i] = file.split('.')[0]\n",
    "\n",
    "partition = {'train':train_list,'validation':val_list}\n",
    "\n",
    "labels = {}\n",
    "for i in range(10000):\n",
    "    name = 'array_number_{}'.format(i)\n",
    "    labels.update({name:target[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so this is pretty neat, you can create a keras callback to display on tensorboard using a simplified summary tf api\n",
    "\n",
    "#and also this is an example of how to change the lr on the fly, which is pretty handy\n",
    "#https://keras.io/callbacks/\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "    file_writer.set_as_default()\n",
    "\"\"\"\n",
    "def lr_schedule(epoch,lr):\n",
    "\n",
    "#Returns a custom learning rate that decreases as epochs progress.\n",
    "    if epoch > 15:\n",
    "        lr = 1e-4\n",
    "    if epoch > 30:\n",
    "        lr = 1e-5\n",
    "\n",
    "    tf.summary.scalar('learning_rate', tensor=lr)\n",
    "    return lr\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "logdir=\"summaries/scalars/\" + str(datetime.datetime.now().timestamp())\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "                                                   histogram_freq=1,\n",
    "                                                   write_graph=False,\n",
    "                                                   write_grads=True,)\n",
    "                                                   #write_images=True)\n",
    "#will it still print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate=learning_rate):\n",
    "    \n",
    "    model = keras.Sequential([])\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(input_shape=(64,64,3),filters=32,kernel_size=6,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=64,kernel_size=5,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "    model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=128,kernel_size=2,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "    model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "    \n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.25)) #best = 0.35\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=64,activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=1,activation=tf.nn.sigmoid)) #tf.nn.softmax for categorical, sigmoid for binary\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=adam, loss=keras.losses.binary_crossentropy(),metrics=['accuracy']) \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "model = create_model(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "steps_to_take = int(len(os.listdir(training_path))/batch_size)\n",
    "val_steps_to_take = int(len(os.listdir(validation_path))/batch_size)\n",
    "                #typically be equal to the number of unique samples if your dataset\n",
    "                #divided by the batch size.\n",
    "\n",
    "print(steps_to_take)\n",
    "print(val_steps_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another callback\n",
    "#reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-8, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\awe2\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py:605: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 72s 2s/step - loss: 0.6084 - acc: 0.6595\n",
      " - 446s - loss: 0.6805 - acc: 0.5816 - val_loss: 0.6084 - val_acc: 0.6595\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=steps_to_take, \n",
    "                    epochs=1,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_steps_to_take,\n",
    "                    verbose=2,\n",
    "                    callbacks=[tensorboard_callback,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_loss, test_acc = model.evaluate(test_images, test_target)\n",
    "#print('Test accuracy:', test_acc)\n",
    "#print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_prob = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source list\n",
    "\"\"\"\n",
    "https://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/\n",
    "\n",
    "https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "\n",
    "https://arxiv.org/pdf/1711.05744.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1807.00807.pdf\n",
    "\n",
    "https://github.com/jameslawlor/kaggle_galaxy_zoo/blob/master/galaxy_zoo_keras.ipynb\n",
    "\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "#https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/48097478\n",
    "\n",
    "https://distill.pub/2018/building-blocks/ what I want to do with this after it is working.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_1:\n",
    "\n",
    "batch_size = 32 #\n",
    "epoch_number = 50\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "overfitted, but not unstable after 50 epochs unlike w/o augmentation.\n",
    "\n",
    "augments= flips, rotations\n",
    "\n",
    "tensorboard: 1561000349.947442\n",
    "\n",
    "architecture:\n",
    "model.add(keras.layers.Conv2D(input_shape=(64,64,5),filters=32,kernel_size=6,padding='same',activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64,kernel_size=5,padding='same',activation=tf.nn.relu))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=128,kernel_size=2,padding='same',activation=tf.nn.relu))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2,))\n",
    "model.add(keras.layers.Dropout(rate=0.25)) #best = 0.25\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(rate=0.25)) #best = 0.35\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(units=64,activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(units=2,activation=tf.nn.softmax))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_2\n",
    "\n",
    "batch_size = 32 #\n",
    "epoch_number = 75\n",
    "learning_rate = 5e-4 \n",
    "\n",
    "same architecture as above\n",
    "\n",
    "tensorboard: 1561040263.807743\n",
    "\n",
    "premise: IDK lol just want something to run while I am working on my real job, but next time I think we will up dropouts,\n",
    "then decrease layers if that still tends to overfit\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_3 \n",
    "\n",
    "we get rid of the last convoluational layer, and increase all dropouts from 0.25 to 0.4\n",
    "\n",
    "else the same.\n",
    "\n",
    "Also, our steps to take was flipped from what they were meant to be; so we were training with very small epochs before.\n",
    "\n",
    "This means that our network does not train at the same speed, lol\n",
    "\n",
    "tensorboard = 1561056117.079296\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_4\n",
    "\n",
    "tried reducing LR to 1e-4, cut the number of filters in the third convolutional layer to 64, and increased dropout to 0.4 on all\n",
    "dropout = 0.25 layers. Newtwork accuracy did not increase, epoch accuracy convered lower than other attempts, newtork in general \n",
    "converged slower. BAD idea, maybe too little parameters. sweet spot might be in the middle somewhere. also did batch size => 64\n",
    "\n",
    "trying to fix network to make better use of the fact that we are in binary mode. , changed loss to binary_crossentropy, changed\n",
    "activation to sigmoid to match. reverted all other parameters to original archiecture, minus the fourth convolutional layer,\n",
    "which I have shown is unneccessary, I think. (incorrect, the best performing model was with that convolutional layer., lr=5e-4)\n",
    "\n",
    "tensorboard = 1561076766.823376\n",
    "\n",
    "Performs about as well as the model_2, we will keep the binary since that is what the paper we based off did.\n",
    "\n",
    "# params  = 2,334,817\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_5\n",
    "\n",
    "We introduce zooming in or out into our data augmentation, and we will introduce the last layer back into the model, since that\n",
    "was the best performing model.  Also am increasing dropout from 0.25 to 0.3 on layers, just to add a bit more regularization.\n",
    "\n",
    "Next thing I can add if this doesnt work is the moving of the center pixel around, and then after that we might consider\n",
    "increasing depth b/c I guess the best performing models have had more depth so far, but it is against intuition to do so.\n",
    "\n",
    "This performed wrose than model_2, which is disheartening because there was more augmentation. (hint, I maybe doing augmentat-\n",
    "ion wrong???)\n",
    "\n",
    "tensorboard=1561130093.100813\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_6\n",
    "\n",
    "Okay, eveything should be exactly the same as the paper we based off of. augmentations shifts of about 5% have been added, as\n",
    "as scaling of each channel to themselves. \"The flux values are normalised to the maximum value in each filter for each galaxy.\"\n",
    "\n",
    "I probably didnt need to waste time and just implement their result fully in the first place, but hey whatever I am learning\n",
    "\n",
    "Litteraly everything is the same as their paper except that we have (64,64) , we are not at the petrosian radius, and we have 5\n",
    "channels. So I will probably mess with architecure from here. I may start with increasring depth since it is one thing I havent\n",
    "tried yet.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "model_idk anymore lol\n",
    "\n",
    "tensorboard=scalars\\1561343515.138241\n",
    "\n",
    "added more layers, increased parameters. compared to model_2, the model didnt perform as well.\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              (None, 64, 64, 32)        5792      \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 64, 64, 64)        51264     \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 32, 32, 128)       32896     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 16, 16, 128)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 16, 16, 256)       131328    \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
    "_________________________________________________________________\n",
    "dropout_4 (Dropout)          (None, 8, 8, 512)         0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 32768)             0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 64)                2097216   \n",
    "_________________________________________________________________\n",
    "dropout_5 (Dropout)          (None, 64)                0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 1)                 65        \n",
    "=================================================================\n",
    "Total params: 3,498,721\n",
    "Trainable params: 3,498,721\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dim = len(os.listdir(test_path))\n",
    "test_targets = list()\n",
    "X = np.empty((first_dim,64,64,5))\n",
    "for i,file in enumerate(os.listdir(test_path)):\n",
    "    X[i,] = np.load(test_path+'\\\\'+file)\n",
    "    index_target = file.split('_')[2]\n",
    "    index_target = int((index_target.split('.')[0]))\n",
    "    test_targets.append(target[index_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = np.zeros((first_dim,64,64,5)) #we will hold all miss_classified data in here\n",
    "cclassified  = np.zeros((first_dim,64,64,5)) #hold all correct classified data in here\n",
    "\n",
    "ccprob = list()\n",
    "msprob = list()\n",
    "cctarget = list()\n",
    "mstarget = list()\n",
    "j=0\n",
    "k=0\n",
    "\n",
    "for i,file in enumerate(os.listdir(test_path)):\n",
    "    if (test_targets[i] == 1 and y_prob[i] > 0.5) or (test_targets[i] == 0 and y_prob[i] <= 0.5):\n",
    "        cclassified[j,] = X[i,]\n",
    "        ccprob.append(y_prob[i])\n",
    "        cctarget.append(test_targets[i])\n",
    "        j+=1\n",
    "    else:\n",
    "        misclassified[k,] = X[i,]\n",
    "        msprob.append(y_prob[i])\n",
    "        mstarget.append(test_targets[i])\n",
    "        k+=1\n",
    "cclassified = cclassified[0:j-1,]\n",
    "misclassified= misclassified[0:k-1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#missclassified\n",
    "start = 5\n",
    "fil = 4\n",
    "fig = plt.subplots(3,3, figsize=(15,15))\n",
    "plt.subplot(3,3,1)\n",
    "\n",
    "plt.imshow(misclassified[1+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[1+ start]))\n",
    "plt.text(10,10,s=str(mstarget[1+ start]))\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "\n",
    "plt.imshow(misclassified[2+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[2+ start]))\n",
    "plt.text(10,10,s=str(mstarget[2+ start]))\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "\n",
    "plt.imshow(misclassified[3+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[3+ start]))\n",
    "plt.text(10,10,s=str(mstarget[3+ start]))\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "\n",
    "plt.imshow(misclassified[4+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[4+ start]))\n",
    "plt.text(10,10,s=str(mstarget[4+ start]))\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "\n",
    "plt.imshow(misclassified[5+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[5+ start]))\n",
    "plt.text(10,10,s=str(mstarget[5+ start]))\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "\n",
    "plt.imshow(misclassified[6+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[6+ start]))\n",
    "plt.text(10,10,s=str(mstarget[6+ start]))\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "\n",
    "plt.imshow(misclassified[7+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[7+ start]))\n",
    "plt.text(10,10,s=str(mstarget[7+ start]))\n",
    "\n",
    "plt.subplot(3,3,8)\n",
    "\n",
    "plt.imshow(misclassified[8+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[8+ start]))\n",
    "plt.text(10,10,s=str(mstarget[8+ start]))\n",
    "\n",
    "plt.subplot(3,3,9)\n",
    "\n",
    "plt.imshow(misclassified[9+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(msprob[9+ start]))\n",
    "plt.text(10,10,s=str(mstarget[9+ start]))\n",
    "\n",
    "plt.savefig('missclassified_5.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(misclassified[14,:,:,1:4])\n",
    "plt.show()\n",
    "plt.imshow(misclassified[14,:,:,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 5\n",
    "fil = 4\n",
    "fig = plt.subplots(3,3, figsize=(15,15))\n",
    "plt.subplot(3,3,1)\n",
    "\n",
    "plt.imshow(cclassified[1+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[1+ start]))\n",
    "plt.text(10,10,s=str(cctarget[1+ start]))\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "\n",
    "plt.imshow(cclassified[2+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[2+ start]))\n",
    "plt.text(10,10,s=str(cctarget[2+ start]))\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "\n",
    "plt.imshow(cclassified[3+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[3+ start]))\n",
    "plt.text(10,10,s=str(cctarget[3+ start]))\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "\n",
    "plt.imshow(cclassified[4+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[4+ start]))\n",
    "plt.text(10,10,s=str(cctarget[4+ start]))\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "\n",
    "plt.imshow(cclassified[5+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[5+ start]))\n",
    "plt.text(10,10,s=str(cctarget[5+ start]))\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "\n",
    "plt.imshow(cclassified[6+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[6+ start]))\n",
    "plt.text(10,10,s=str(cctarget[6+ start]))\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "\n",
    "plt.imshow(cclassified[7+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[7+ start]))\n",
    "plt.text(10,10,s=str(cctarget[7+ start]))\n",
    "\n",
    "plt.subplot(3,3,8)\n",
    "\n",
    "plt.imshow(cclassified[8+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[8+ start]))\n",
    "plt.text(10,10,s=str(cctarget[8+ start]))\n",
    "\n",
    "plt.subplot(3,3,9)\n",
    "\n",
    "plt.imshow(cclassified[9+ start,:,:,fil]) #red filter\n",
    "plt.text(10,5,s=str(ccprob[9+ start]))\n",
    "plt.text(10,10,s=str(cctarget[9+ start]))\n",
    "\n",
    "plt.savefig('cclassified_5.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
